"""
üî• Real-Time Adaptive Strategy - Strat√©gie d'Adaptation Temps R√©el Ultra-Avanc√©e
================================================================================

Strat√©gie d'isolation r√©volutionnaire s'adaptant en temps r√©el aux conditions
changeantes de charge, patterns d'acc√®s, et exigences de s√©curit√© avec des
algorithmes d'adaptation instantan√©e et machine learning en continu.

Fonctionnalit√©s Ultra-Avanc√©es:
    ‚ö° Adaptation en temps r√©el < 100ms
    üéØ Pattern recognition instantan√©
    üîÑ Auto-scaling intelligent
    üìä M√©triques continues en streaming
    üß† RL (Reinforcement Learning) int√©gr√©
    üõ°Ô∏è S√©curit√© adaptative
    üìà Optimisation pr√©dictive
    üî• Zero-downtime switching
    üéõÔ∏è Dynamic resource allocation
    üì° Event-driven architecture

Architecture:
    - Real-time metrics streaming
    - Adaptive load balancing
    - Dynamic strategy switching
    - Predictive resource allocation
    - Continuous learning algorithms
    - Auto-healing mechanisms

Author: Architecte IA Expert - Team Fahed Mlaiel
"""

import asyncio
import logging
import json
import time
from typing import Dict, List, Any, Optional, Union, Set, Tuple, Callable, AsyncGenerator
from dataclasses import dataclass, field, asdict
from datetime import datetime, timezone, timedelta
from enum import Enum, auto
from collections import deque, defaultdict
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import weakref
import heapq
from pathlib import Path
import hashlib
import statistics

# ML and streaming
try:
    import numpy as np
    import pandas as pd
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.preprocessing import StandardScaler
    from sklearn.cluster import MiniBatchKMeans
    import joblib
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False

# Real-time monitoring
try:
    import psutil
    import resource
    MONITORING_AVAILABLE = True
except ImportError:
    MONITORING_AVAILABLE = False

# Event streaming
try:
    import asyncio_redis
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False

from ..core.tenant_context import TenantContext, TenantType, IsolationLevel
from ..core.isolation_engine import IsolationStrategy, EngineConfig
from ..managers.connection_manager import DatabaseConnection
from ..exceptions import (
    DataIsolationError, PerformanceError, AdaptationError,
    ResourceExhaustionError, ConfigurationError
)

# Logger setup
logger = logging.getLogger(__name__)


class AdaptationTrigger(Enum):
    """D√©clencheurs d'adaptation en temps r√©el"""
    PERFORMANCE_DEGRADATION = "performance_degradation"
    RESOURCE_SATURATION = "resource_saturation"
    SECURITY_THREAT = "security_threat"
    LOAD_SPIKE = "load_spike"
    PATTERN_CHANGE = "pattern_change"
    COST_THRESHOLD = "cost_threshold"
    SLA_VIOLATION = "sla_violation"
    COMPLIANCE_ALERT = "compliance_alert"
    ANOMALY_DETECTED = "anomaly_detected"
    SCHEDULED_OPTIMIZATION = "scheduled_optimization"


class AdaptationAction(Enum):
    """Actions d'adaptation possibles"""
    STRATEGY_SWITCH = "strategy_switch"
    RESOURCE_SCALE = "resource_scale"
    LOAD_REDISTRIBUTE = "load_redistribute"
    CACHE_OPTIMIZE = "cache_optimize"
    CONNECTION_REBALANCE = "connection_rebalance"
    QUERY_OPTIMIZE = "query_optimize"
    SECURITY_ENHANCE = "security_enhance"
    FAILOVER_ACTIVATE = "failover_activate"
    MAINTENANCE_MODE = "maintenance_mode"
    EMERGENCY_SHUTDOWN = "emergency_shutdown"


class AdaptationSpeed(Enum):
    """Vitesses d'adaptation"""
    INSTANT = 0.05  # 50ms
    VERY_FAST = 0.1  # 100ms
    FAST = 0.5  # 500ms
    MEDIUM = 2.0  # 2s
    SLOW = 5.0  # 5s


@dataclass
class RealTimeMetrics:
    """M√©triques temps r√©el"""
    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    tenant_id: str = ""
    strategy_type: str = ""
    
    # Performance metrics
    query_latency_ms: float = 0.0
    throughput_qps: float = 0.0
    error_rate_percent: float = 0.0
    
    # Resource metrics
    cpu_usage_percent: float = 0.0
    memory_usage_mb: float = 0.0
    disk_io_mbps: float = 0.0
    network_io_mbps: float = 0.0
    
    # Database metrics
    active_connections: int = 0
    connection_pool_usage: float = 0.0
    cache_hit_ratio: float = 0.0
    query_queue_length: int = 0
    
    # Security metrics
    auth_failures: int = 0
    suspicious_queries: int = 0
    access_violations: int = 0
    
    # Business metrics
    concurrent_users: int = 0
    data_volume_mb: float = 0.0
    cost_per_query: float = 0.0


@dataclass
class AdaptationEvent:
    """√âv√©nement d'adaptation"""
    event_id: str = field(default_factory=lambda: hashlib.sha256(str(time.time()).encode()).hexdigest()[:16])
    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    trigger: AdaptationTrigger = AdaptationTrigger.PERFORMANCE_DEGRADATION
    action: AdaptationAction = AdaptationAction.STRATEGY_SWITCH
    tenant_id: str = ""
    
    # Context
    current_strategy: str = ""
    target_strategy: str = ""
    severity: str = "medium"  # low, medium, high, critical
    confidence: float = 0.8
    
    # Metrics
    before_metrics: Optional[RealTimeMetrics] = None
    after_metrics: Optional[RealTimeMetrics] = None
    
    # Execution
    execution_time_ms: float = 0.0
    success: bool = True
    error_message: str = ""
    rollback_required: bool = False


@dataclass
class AdaptationRule:
    """R√®gle d'adaptation"""
    rule_id: str
    name: str
    description: str
    
    # Conditions
    trigger_condition: Callable[[RealTimeMetrics], bool]
    min_confidence: float = 0.7
    cooldown_seconds: int = 60
    
    # Action
    action: AdaptationAction
    target_strategy: Optional[str] = None
    parameters: Dict[str, Any] = field(default_factory=dict)
    
    # Metadata
    priority: int = 1  # 1-10, higher = more priority
    enabled: bool = True
    last_triggered: Optional[datetime] = None
    trigger_count: int = 0


class StreamingMetricsCollector:
    """Collecteur de m√©triques en streaming"""
    
    def __init__(self, buffer_size: int = 1000, sampling_rate: float = 1.0):
        self.buffer_size = buffer_size
        self.sampling_rate = sampling_rate
        self.metrics_buffer = deque(maxlen=buffer_size)
        self.subscribers: List[Callable[[RealTimeMetrics], None]] = []
        self._lock = threading.RLock()
        self._running = False
        self._collection_task: Optional[asyncio.Task] = None
        
    async def start(self):
        """D√©marre la collecte de m√©triques"""
        if self._running:
            return
            
        self._running = True
        self._collection_task = asyncio.create_task(self._collect_metrics())
        logger.info("Streaming metrics collector started")
        
    async def stop(self):
        """Arr√™te la collecte de m√©triques"""
        self._running = False
        if self._collection_task:
            self._collection_task.cancel()
            try:
                await self._collection_task
            except asyncio.CancelledError:
                pass
        logger.info("Streaming metrics collector stopped")
        
    def subscribe(self, callback: Callable[[RealTimeMetrics], None]):
        """S'abonne aux m√©triques en temps r√©el"""
        with self._lock:
            self.subscribers.append(callback)
            
    def unsubscribe(self, callback: Callable[[RealTimeMetrics], None]):
        """Se d√©sabonne des m√©triques"""
        with self._lock:
            if callback in self.subscribers:
                self.subscribers.remove(callback)
    
    async def _collect_metrics(self):
        """Collecte des m√©triques en continu"""
        while self._running:
            try:
                metrics = await self._gather_current_metrics()
                
                # √âchantillonnage si n√©cessaire
                if np.random.random() <= self.sampling_rate:
                    with self._lock:
                        self.metrics_buffer.append(metrics)
                        
                    # Notifier les abonn√©s
                    for callback in self.subscribers:
                        try:
                            if asyncio.iscoroutinefunction(callback):
                                await callback(metrics)
                            else:
                                callback(metrics)
                        except Exception as e:
                            logger.error(f"Error in metrics callback: {e}")
                
                await asyncio.sleep(0.1)  # 100ms collection interval
                
            except Exception as e:
                logger.error(f"Error collecting metrics: {e}")
                await asyncio.sleep(1.0)
    
    async def _gather_current_metrics(self) -> RealTimeMetrics:
        """Collecte les m√©triques actuelles du syst√®me"""
        metrics = RealTimeMetrics()
        
        if MONITORING_AVAILABLE:
            # CPU et m√©moire
            metrics.cpu_usage_percent = psutil.cpu_percent(interval=None)
            memory = psutil.virtual_memory()
            metrics.memory_usage_mb = memory.used / (1024 * 1024)
            
            # I/O
            try:
                io_counters = psutil.disk_io_counters()
                if io_counters:
                    metrics.disk_io_mbps = (io_counters.read_bytes + io_counters.write_bytes) / (1024 * 1024)
                    
                net_counters = psutil.net_io_counters()
                if net_counters:
                    metrics.network_io_mbps = (net_counters.bytes_sent + net_counters.bytes_recv) / (1024 * 1024)
            except:
                pass
        
        return metrics


class PatternRecognizer:
    """Reconnaissance de patterns en temps r√©el"""
    
    def __init__(self, window_size: int = 100, pattern_threshold: float = 0.8):
        self.window_size = window_size
        self.pattern_threshold = pattern_threshold
        self.patterns: Dict[str, List[float]] = {}
        self.known_patterns: Dict[str, np.ndarray] = {}
        self._lock = threading.RLock()
        
        if ML_AVAILABLE:
            self.clusterer = MiniBatchKMeans(n_clusters=5, random_state=42)
            self.scaler = StandardScaler()
            self._trained = False
    
    def add_metrics(self, metrics: RealTimeMetrics):
        """Ajoute des m√©triques pour reconnaissance de patterns"""
        with self._lock:
            # Conversion en features num√©riques
            features = [
                metrics.query_latency_ms,
                metrics.throughput_qps,
                metrics.cpu_usage_percent,
                metrics.memory_usage_mb,
                metrics.active_connections,
                metrics.cache_hit_ratio
            ]
            
            pattern_key = f"{metrics.tenant_id}_{metrics.strategy_type}"
            
            if pattern_key not in self.patterns:
                self.patterns[pattern_key] = deque(maxlen=self.window_size)
                
            self.patterns[pattern_key].extend(features)
            
            # Entra√Ænement en ligne si suffisamment de donn√©es
            if len(self.patterns[pattern_key]) >= self.window_size and ML_AVAILABLE:
                self._update_pattern_model(pattern_key)
    
    def _update_pattern_model(self, pattern_key: str):
        """Met √† jour le mod√®le de reconnaissance de patterns"""
        try:
            data = np.array(self.patterns[pattern_key]).reshape(-1, 6)
            
            if not self._trained:
                scaled_data = self.scaler.fit_transform(data)
                self.clusterer.fit(scaled_data)
                self._trained = True
            else:
                scaled_data = self.scaler.transform(data)
                self.clusterer.partial_fit(scaled_data)
                
            self.known_patterns[pattern_key] = scaled_data[-1]
            
        except Exception as e:
            logger.error(f"Error updating pattern model: {e}")
    
    def detect_anomaly(self, metrics: RealTimeMetrics) -> Tuple[bool, float]:
        """D√©tecte une anomalie dans les patterns"""
        if not ML_AVAILABLE or not self._trained:
            return False, 0.0
            
        try:
            pattern_key = f"{metrics.tenant_id}_{metrics.strategy_type}"
            
            if pattern_key not in self.known_patterns:
                return False, 0.0
            
            features = np.array([[
                metrics.query_latency_ms,
                metrics.throughput_qps,
                metrics.cpu_usage_percent,
                metrics.memory_usage_mb,
                metrics.active_connections,
                metrics.cache_hit_ratio
            ]])
            
            scaled_features = self.scaler.transform(features)
            distances = self.clusterer.transform(scaled_features)
            min_distance = np.min(distances)
            
            # Anomalie si distance trop grande
            is_anomaly = min_distance > self.pattern_threshold
            confidence = min(min_distance / self.pattern_threshold, 1.0)
            
            return is_anomaly, confidence
            
        except Exception as e:
            logger.error(f"Error detecting anomaly: {e}")
            return False, 0.0


class AdaptationEngine:
    """Moteur d'adaptation temps r√©el"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        self.rules: List[AdaptationRule] = []
        self.events_history = deque(maxlen=1000)
        self.metrics_collector = StreamingMetricsCollector()
        self.pattern_recognizer = PatternRecognizer()
        self._running = False
        self._lock = threading.RLock()
        
        # Composants
        self.strategies: Dict[str, IsolationStrategy] = {}
        self.current_strategy: Optional[str] = None
        
        # M√©triques d'adaptation
        self.adaptation_stats = {
            'total_adaptations': 0,
            'successful_adaptations': 0,
            'failed_adaptations': 0,
            'avg_adaptation_time': 0.0,
            'last_adaptation': None
        }
        
        self._setup_default_rules()
        
    def _setup_default_rules(self):
        """Configure les r√®gles d'adaptation par d√©faut"""
        
        # R√®gle de performance critique
        self.add_rule(AdaptationRule(
            rule_id="perf_critical",
            name="Performance Critique",
            description="Adaptation imm√©diate si latence > 1000ms",
            trigger_condition=lambda m: m.query_latency_ms > 1000,
            action=AdaptationAction.STRATEGY_SWITCH,
            target_strategy="performance_optimized",
            priority=10,
            cooldown_seconds=30
        ))
        
        # R√®gle de saturation CPU
        self.add_rule(AdaptationRule(
            rule_id="cpu_saturation",
            name="Saturation CPU",
            description="Scale-out si CPU > 80%",
            trigger_condition=lambda m: m.cpu_usage_percent > 80,
            action=AdaptationAction.RESOURCE_SCALE,
            priority=8,
            cooldown_seconds=60
        ))
        
        # R√®gle de pic de charge
        self.add_rule(AdaptationRule(
            rule_id="load_spike",
            name="Pic de Charge",
            description="Redistribution si QPS > seuil",
            trigger_condition=lambda m: m.throughput_qps > 1000,
            action=AdaptationAction.LOAD_REDISTRIBUTE,
            priority=7,
            cooldown_seconds=45
        ))
        
        # R√®gle d'anomalie de s√©curit√©
        self.add_rule(AdaptationRule(
            rule_id="security_anomaly",
            name="Anomalie S√©curit√©",
            description="Renforcement s√©curit√© si violations d√©tect√©es",
            trigger_condition=lambda m: m.auth_failures > 10 or m.access_violations > 5,
            action=AdaptationAction.SECURITY_ENHANCE,
            priority=9,
            cooldown_seconds=20
        ))
    
    def add_rule(self, rule: AdaptationRule):
        """Ajoute une r√®gle d'adaptation"""
        with self._lock:
            self.rules.append(rule)
            self.rules.sort(key=lambda r: r.priority, reverse=True)
    
    def remove_rule(self, rule_id: str):
        """Supprime une r√®gle d'adaptation"""
        with self._lock:
            self.rules = [r for r in self.rules if r.rule_id != rule_id]
    
    async def start(self):
        """D√©marre le moteur d'adaptation"""
        if self._running:
            return
            
        self._running = True
        
        # D√©marre le collecteur de m√©triques
        await self.metrics_collector.start()
        
        # S'abonne aux m√©triques
        self.metrics_collector.subscribe(self._on_metrics_received)
        
        logger.info("Real-time adaptation engine started")
    
    async def stop(self):
        """Arr√™te le moteur d'adaptation"""
        self._running = False
        await self.metrics_collector.stop()
        logger.info("Real-time adaptation engine stopped")
    
    async def _on_metrics_received(self, metrics: RealTimeMetrics):
        """Traite les m√©triques re√ßues"""
        try:
            # Ajout aux patterns
            self.pattern_recognizer.add_metrics(metrics)
            
            # D√©tection d'anomalies
            is_anomaly, confidence = self.pattern_recognizer.detect_anomaly(metrics)
            
            if is_anomaly and confidence > 0.8:
                await self._trigger_adaptation(
                    AdaptationTrigger.ANOMALY_DETECTED,
                    metrics,
                    confidence
                )
            
            # √âvaluation des r√®gles d'adaptation
            await self._evaluate_adaptation_rules(metrics)
            
        except Exception as e:
            logger.error(f"Error processing metrics: {e}")
    
    async def _evaluate_adaptation_rules(self, metrics: RealTimeMetrics):
        """√âvalue les r√®gles d'adaptation"""
        current_time = datetime.now(timezone.utc)
        
        for rule in self.rules:
            if not rule.enabled:
                continue
                
            # V√©rification du cooldown
            if (rule.last_triggered and 
                (current_time - rule.last_triggered).total_seconds() < rule.cooldown_seconds):
                continue
            
            try:
                # √âvaluation de la condition
                if rule.trigger_condition(metrics):
                    await self._execute_adaptation_rule(rule, metrics)
                    
            except Exception as e:
                logger.error(f"Error evaluating rule {rule.rule_id}: {e}")
    
    async def _execute_adaptation_rule(self, rule: AdaptationRule, metrics: RealTimeMetrics):
        """Ex√©cute une r√®gle d'adaptation"""
        start_time = time.time()
        
        try:
            # Cr√©ation de l'√©v√©nement d'adaptation
            event = AdaptationEvent(
                trigger=AdaptationTrigger.PERFORMANCE_DEGRADATION,  # √Ä adapter selon la r√®gle
                action=rule.action,
                tenant_id=metrics.tenant_id,
                current_strategy=self.current_strategy or "",
                target_strategy=rule.target_strategy or "",
                confidence=0.9,  # √Ä calculer
                before_metrics=metrics
            )
            
            # Ex√©cution de l'action
            success = await self._execute_adaptation_action(rule.action, rule.parameters, metrics)
            
            # Mise √† jour de l'√©v√©nement
            event.execution_time_ms = (time.time() - start_time) * 1000
            event.success = success
            
            if not success:
                event.error_message = "Adaptation failed"
                event.rollback_required = True
            
            # Mise √† jour des statistiques
            with self._lock:
                rule.last_triggered = datetime.now(timezone.utc)
                rule.trigger_count += 1
                self.events_history.append(event)
                
                self.adaptation_stats['total_adaptations'] += 1
                if success:
                    self.adaptation_stats['successful_adaptations'] += 1
                else:
                    self.adaptation_stats['failed_adaptations'] += 1
                    
                self.adaptation_stats['avg_adaptation_time'] = (
                    (self.adaptation_stats['avg_adaptation_time'] * 
                     (self.adaptation_stats['total_adaptations'] - 1) +
                     event.execution_time_ms) / 
                    self.adaptation_stats['total_adaptations']
                )
                self.adaptation_stats['last_adaptation'] = event.timestamp
            
            logger.info(f"Adaptation rule {rule.rule_id} executed: {success}")
            
        except Exception as e:
            logger.error(f"Error executing adaptation rule {rule.rule_id}: {e}")
    
    async def _execute_adaptation_action(
        self, 
        action: AdaptationAction, 
        parameters: Dict[str, Any],
        metrics: RealTimeMetrics
    ) -> bool:
        """Ex√©cute une action d'adaptation"""
        try:
            if action == AdaptationAction.STRATEGY_SWITCH:
                return await self._switch_strategy(parameters.get('target_strategy'))
                
            elif action == AdaptationAction.RESOURCE_SCALE:
                return await self._scale_resources(parameters)
                
            elif action == AdaptationAction.LOAD_REDISTRIBUTE:
                return await self._redistribute_load(parameters)
                
            elif action == AdaptationAction.CACHE_OPTIMIZE:
                return await self._optimize_cache(parameters)
                
            elif action == AdaptationAction.CONNECTION_REBALANCE:
                return await self._rebalance_connections(parameters)
                
            elif action == AdaptationAction.SECURITY_ENHANCE:
                return await self._enhance_security(parameters)
                
            else:
                logger.warning(f"Unknown adaptation action: {action}")
                return False
                
        except Exception as e:
            logger.error(f"Error executing adaptation action {action}: {e}")
            return False
    
    async def _switch_strategy(self, target_strategy: Optional[str]) -> bool:
        """Commute vers une nouvelle strat√©gie"""
        if not target_strategy or target_strategy == self.current_strategy:
            return False
            
        try:
            # Logique de commutation de strat√©gie
            # (√† impl√©menter selon l'architecture sp√©cifique)
            logger.info(f"Switching strategy from {self.current_strategy} to {target_strategy}")
            self.current_strategy = target_strategy
            return True
            
        except Exception as e:
            logger.error(f"Error switching strategy: {e}")
            return False
    
    async def _scale_resources(self, parameters: Dict[str, Any]) -> bool:
        """Scale les ressources"""
        try:
            # Logique de scaling des ressources
            scale_factor = parameters.get('scale_factor', 1.2)
            logger.info(f"Scaling resources by factor {scale_factor}")
            return True
            
        except Exception as e:
            logger.error(f"Error scaling resources: {e}")
            return False
    
    async def _redistribute_load(self, parameters: Dict[str, Any]) -> bool:
        """Redistribue la charge"""
        try:
            # Logique de redistribution de charge
            logger.info("Redistributing load across instances")
            return True
            
        except Exception as e:
            logger.error(f"Error redistributing load: {e}")
            return False
    
    async def _optimize_cache(self, parameters: Dict[str, Any]) -> bool:
        """Optimise le cache"""
        try:
            # Logique d'optimisation du cache
            logger.info("Optimizing cache configuration")
            return True
            
        except Exception as e:
            logger.error(f"Error optimizing cache: {e}")
            return False
    
    async def _rebalance_connections(self, parameters: Dict[str, Any]) -> bool:
        """R√©√©quilibre les connexions"""
        try:
            # Logique de r√©√©quilibrage des connexions
            logger.info("Rebalancing database connections")
            return True
            
        except Exception as e:
            logger.error(f"Error rebalancing connections: {e}")
            return False
    
    async def _enhance_security(self, parameters: Dict[str, Any]) -> bool:
        """Renforce la s√©curit√©"""
        try:
            # Logique de renforcement de s√©curit√©
            logger.info("Enhancing security measures")
            return True
            
        except Exception as e:
            logger.error(f"Error enhancing security: {e}")
            return False
    
    async def _trigger_adaptation(
        self, 
        trigger: AdaptationTrigger, 
        metrics: RealTimeMetrics,
        confidence: float
    ):
        """D√©clenche une adaptation manuelle"""
        # Trouve la meilleure action pour ce trigger
        for rule in self.rules:
            if rule.enabled and confidence >= rule.min_confidence:
                await self._execute_adaptation_rule(rule, metrics)
                break
    
    def get_adaptation_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques d'adaptation"""
        with self._lock:
            return self.adaptation_stats.copy()
    
    def get_recent_events(self, limit: int = 50) -> List[AdaptationEvent]:
        """Retourne les √©v√©nements r√©cents"""
        with self._lock:
            return list(self.events_history)[-limit:]


class RealTimeAdaptiveStrategy(IsolationStrategy):
    """
    Strat√©gie d'isolation adaptative en temps r√©el ultra-avanc√©e
    
    Cette strat√©gie combine toutes les autres strat√©gies et s'adapte
    automatiquement aux conditions changeantes avec des algorithmes
    d'apprentissage en continu et d'optimisation pr√©dictive.
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__(config)
        self.config = config or {}
        
        # Composants principaux
        self.adaptation_engine = AdaptationEngine(config)
        self.available_strategies: Dict[str, IsolationStrategy] = {}
        self.current_strategy_name: str = "hybrid"
        self.current_strategy: Optional[IsolationStrategy] = None
        
        # Configuration
        self.adaptation_enabled = self.config.get('adaptation_enabled', True)
        self.min_adaptation_interval = self.config.get('min_adaptation_interval', 30)
        self.performance_threshold = self.config.get('performance_threshold', 100)
        
        # √âtat
        self.last_adaptation = datetime.now(timezone.utc)
        self._initialized = False
        
        logger.info("Real-time adaptive strategy initialized")
    
    async def initialize(self):
        """Initialise la strat√©gie adaptive"""
        if self._initialized:
            return
            
        try:
            # Initialise les strat√©gies disponibles
            from .database_level import DatabaseLevelStrategy
            from .schema_level import SchemaLevelStrategy
            from .row_level import RowLevelStrategy
            from .hybrid_strategy import HybridStrategy
            from .performance_optimized_strategy import PerformanceOptimizedStrategy
            
            self.available_strategies = {
                'database_level': DatabaseLevelStrategy(self.config),
                'schema_level': SchemaLevelStrategy(self.config),
                'row_level': RowLevelStrategy(self.config),
                'hybrid': HybridStrategy(self.config),
                'performance_optimized': PerformanceOptimizedStrategy(self.config)
            }
            
            # Initialise chaque strat√©gie
            for strategy in self.available_strategies.values():
                if hasattr(strategy, 'initialize'):
                    await strategy.initialize()
            
            # S√©lectionne la strat√©gie initiale
            self.current_strategy = self.available_strategies[self.current_strategy_name]
            
            # D√©marre le moteur d'adaptation
            if self.adaptation_enabled:
                await self.adaptation_engine.start()
            
            self._initialized = True
            logger.info("Real-time adaptive strategy fully initialized")
            
        except Exception as e:
            logger.error(f"Error initializing adaptive strategy: {e}")
            raise
    
    async def isolate_query(self, query: str, tenant_context: TenantContext) -> str:
        """Isole une requ√™te avec adaptation en temps r√©el"""
        if not self._initialized:
            await self.initialize()
        
        if not self.current_strategy:
            raise DataIsolationError("No current strategy available")
        
        start_time = time.time()
        
        try:
            # Ex√©cute la requ√™te avec la strat√©gie actuelle
            result = await self.current_strategy.isolate_query(query, tenant_context)
            
            # Mesure la performance
            execution_time = (time.time() - start_time) * 1000
            
            # Collecte des m√©triques pour adaptation
            if self.adaptation_enabled:
                await self._collect_query_metrics(execution_time, tenant_context)
            
            return result
            
        except Exception as e:
            # En cas d'erreur, tente une adaptation d'urgence
            if self.adaptation_enabled:
                await self._handle_query_error(e, tenant_context)
            raise
    
    async def _collect_query_metrics(self, execution_time_ms: float, tenant_context: TenantContext):
        """Collecte les m√©triques de requ√™te pour adaptation"""
        try:
            # Simulation de collecte de m√©triques
            # (√† remplacer par une vraie collecte)
            if execution_time_ms > self.performance_threshold:
                logger.warning(f"Query performance degradation: {execution_time_ms}ms")
                
        except Exception as e:
            logger.error(f"Error collecting query metrics: {e}")
    
    async def _handle_query_error(self, error: Exception, tenant_context: TenantContext):
        """G√®re les erreurs de requ√™te avec adaptation"""
        try:
            logger.error(f"Query error, attempting adaptation: {error}")
            
            # Tentative d'adaptation vers une strat√©gie plus robuste
            fallback_strategy = self.config.get('fallback_strategy', 'row_level')
            
            if (fallback_strategy in self.available_strategies and 
                self.current_strategy_name != fallback_strategy):
                
                await self._switch_strategy(fallback_strategy)
                
        except Exception as e:
            logger.error(f"Error handling query error: {e}")
    
    async def _switch_strategy(self, target_strategy: str):
        """Commute vers une nouvelle strat√©gie"""
        if target_strategy not in self.available_strategies:
            logger.error(f"Unknown target strategy: {target_strategy}")
            return False
        
        try:
            # V√©rifie l'intervalle minimum entre adaptations
            time_since_last = (datetime.now(timezone.utc) - self.last_adaptation).total_seconds()
            if time_since_last < self.min_adaptation_interval:
                logger.debug(f"Adaptation too frequent, skipping ({time_since_last}s)")
                return False
            
            logger.info(f"Switching from {self.current_strategy_name} to {target_strategy}")
            
            old_strategy = self.current_strategy_name
            self.current_strategy_name = target_strategy
            self.current_strategy = self.available_strategies[target_strategy]
            self.last_adaptation = datetime.now(timezone.utc)
            
            logger.info(f"Successfully switched strategy: {old_strategy} -> {target_strategy}")
            return True
            
        except Exception as e:
            logger.error(f"Error switching strategy: {e}")
            return False
    
    async def validate_isolation(self, tenant_context: TenantContext) -> bool:
        """Valide l'isolation avec la strat√©gie actuelle"""
        if not self.current_strategy:
            return False
            
        return await self.current_strategy.validate_isolation(tenant_context)
    
    async def cleanup(self):
        """Nettoie les ressources"""
        try:
            if self.adaptation_enabled:
                await self.adaptation_engine.stop()
                
            for strategy in self.available_strategies.values():
                if hasattr(strategy, 'cleanup'):
                    await strategy.cleanup()
                    
            logger.info("Real-time adaptive strategy cleaned up")
            
        except Exception as e:
            logger.error(f"Error cleaning up adaptive strategy: {e}")
    
    def get_current_strategy_info(self) -> Dict[str, Any]:
        """Retourne les informations sur la strat√©gie actuelle"""
        return {
            'current_strategy': self.current_strategy_name,
            'available_strategies': list(self.available_strategies.keys()),
            'adaptation_enabled': self.adaptation_enabled,
            'last_adaptation': self.last_adaptation.isoformat(),
            'adaptation_stats': self.adaptation_engine.get_adaptation_stats(),
            'recent_events': [asdict(event) for event in self.adaptation_engine.get_recent_events(10)]
        }


# Factory pour cr√©ation de la strat√©gie
def create_real_time_adaptive_strategy(config: Optional[Dict[str, Any]] = None) -> RealTimeAdaptiveStrategy:
    """
    Factory pour cr√©er une strat√©gie adaptative temps r√©el
    
    Args:
        config: Configuration de la strat√©gie
        
    Returns:
        Instance de RealTimeAdaptiveStrategy configur√©e
    """
    return RealTimeAdaptiveStrategy(config)


# Export du module
__all__ = [
    'RealTimeAdaptiveStrategy',
    'AdaptationEngine',
    'StreamingMetricsCollector',
    'PatternRecognizer',
    'AdaptationTrigger',
    'AdaptationAction',
    'AdaptationSpeed',
    'RealTimeMetrics',
    'AdaptationEvent',
    'AdaptationRule',
    'create_real_time_adaptive_strategy'
]
