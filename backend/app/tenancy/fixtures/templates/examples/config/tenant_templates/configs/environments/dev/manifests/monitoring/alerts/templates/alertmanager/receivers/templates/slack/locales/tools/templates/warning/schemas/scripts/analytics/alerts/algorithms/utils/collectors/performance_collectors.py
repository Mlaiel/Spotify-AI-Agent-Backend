"""
Spotify AI Agent - Performance Collectors Module Ultra-Avanc√©
============================================================

Collecteurs ultra-avanc√©s pour le monitoring de performance syst√®me
dans l'environnement multi-tenant haute performance. Architecture entreprise
avec d√©tection d'anomalies, pr√©dictions ML et alerting intelligent.

üéØ COLLECTEURS DISPONIBLES:
‚îú‚îÄ‚îÄ SystemPerformanceCollector: CPU, m√©moire, disque, r√©seau (temps r√©el)
‚îú‚îÄ‚îÄ DatabasePerformanceCollector: PostgreSQL, TimescaleDB, requ√™tes SQL
‚îú‚îÄ‚îÄ RedisPerformanceCollector: Cache Redis Cluster, performance m√©moire
‚îú‚îÄ‚îÄ APIPerformanceCollector: Latence API, throughput, codes d'erreur
‚îú‚îÄ‚îÄ NetworkPerformanceCollector: Bande passante, latence, paquets perdus
‚îú‚îÄ‚îÄ CachePerformanceCollector: Hit ratio, √©victions, distribution de cache
‚îú‚îÄ‚îÄ LoadBalancerCollector: Distribution de charge, health checks
‚îú‚îÄ‚îÄ CDNPerformanceCollector: Performance CDN, cache hits globaux
‚îú‚îÄ‚îÄ KubernetesPerformanceCollector: Pods, nodes, ressources K8s
‚îî‚îÄ‚îÄ ApplicationPerformanceCollector: M√©triques application custom

üöÄ FONCTIONNALIT√âS ENTERPRISE:
‚Ä¢ Collecte temps r√©el haute fr√©quence (>10K m√©triques/sec)
‚Ä¢ D√©tection d'anomalies bas√©e sur Machine Learning
‚Ä¢ Pr√©dictions de performance avec mod√®les ARIMA/LSTM
‚Ä¢ Alerting intelligent avec r√©duction de bruit
‚Ä¢ Corr√©lation multi-m√©triques automatique
‚Ä¢ Profiling d√©taill√© des ressources critiques
‚Ä¢ Auto-tuning des seuils bas√© sur l'historique
‚Ä¢ Dashboards adaptatifs temps r√©el

üë• √âQUIPE DE D√âVELOPPEMENT:
üèÜ Lead Dev + Architecte IA: Fahed Mlaiel
üöÄ D√©veloppeur Backend Senior (Python/FastAPI/Django)
üß† Ing√©nieur Machine Learning (TensorFlow/PyTorch/Hugging Face)  
üíæ DBA & Data Engineer (PostgreSQL/Redis/MongoDB)
üîí Sp√©cialiste S√©curit√© Backend
üèóÔ∏è Architecte Microservices

üìä PERFORMANCES CIBLES:
‚Ä¢ Latence P99: <5ms pour collecte locale
‚Ä¢ Throughput: >100K m√©triques/seconde
‚Ä¢ Pr√©cision anomalies: >95%
‚Ä¢ Faux positifs: <2%
‚Ä¢ Disponibilit√©: 99.99%
"""

import psutil
import asyncio
import aioredis
import asyncpg
import pymongo
import aiohttp
import aiofiles
import aiokafka
import platform
import socket
import threading
from typing import Dict, Any, List, Optional, Union, Tuple, Callable
from datetime import datetime, timedelta, timezone
import statistics
import json
import time
import math
import numpy as np
import pandas as pd
from dataclasses import dataclass, field
from collections import deque, defaultdict
from concurrent.futures import ThreadPoolExecutor
import structlog
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
import joblib
import warnings
warnings.filterwarnings('ignore')

from .base import BaseCollector
from .config import TenantConfig
from .exceptions import CollectorException, DataCollectionError
from .utils import (
    PerformanceProfiler, MetricsAggregator, AnomalyDetector,
    cache_result, measure_performance
)
from .monitoring import global_metrics_collector, global_health_monitor
from .patterns import CircuitBreaker, RetryManager, RateLimiter

logger = structlog.get_logger(__name__)


@dataclass
class PerformanceMetrics:
    """Structure enrichie des m√©triques de performance."""
    timestamp: datetime
    tenant_id: str
    collector_type: str
    cpu_percent: float
    memory_percent: float
    disk_usage: Dict[str, float]
    network_io: Dict[str, int]
    process_count: int
    load_average: List[float]
    temperature: Optional[float] = None
    anomaly_score: Optional[float] = None
    health_score: float = 100.0
    predictions: Dict[str, Any] = field(default_factory=dict)


class CPUMetricsCollector:
    """Collecteur sp√©cialis√© pour les m√©triques CPU."""
    
    def __init__(self):
        self.history = deque(maxlen=100)
        self.baseline_established = False
        self.baseline_metrics = {}
    
    async def collect(self) -> Dict[str, Any]:
        """Collecte d√©taill√©e des m√©triques CPU."""
        try:
            # M√©triques de base
            cpu_percent_total = psutil.cpu_percent(interval=0.1)
            cpu_percent_per_core = psutil.cpu_percent(interval=0.1, percpu=True)
            
            # Fr√©quences CPU
            cpu_freq = psutil.cpu_freq()
            cpu_freq_per_core = psutil.cpu_freq(percpu=True)
            
            # Statistiques CPU
            cpu_stats = psutil.cpu_stats()
            
            # Temps CPU d√©taill√©s
            cpu_times = psutil.cpu_times()
            cpu_times_per_core = psutil.cpu_times(percpu=True)
            
            cpu_data = {
                "usage_percent": cpu_percent_total,
                "usage_per_core": cpu_percent_per_core,
                "core_count": psutil.cpu_count(logical=False),
                "logical_core_count": psutil.cpu_count(logical=True),
                "frequency": {
                    "current": cpu_freq.current if cpu_freq else None,
                    "min": cpu_freq.min if cpu_freq else None,
                    "max": cpu_freq.max if cpu_freq else None,
                    "per_core": [
                        {
                            "current": freq.current,
                            "min": freq.min,
                            "max": freq.max
                        } if freq else None
                        for freq in (cpu_freq_per_core or [])
                    ]
                },
                "stats": {
                    "context_switches": cpu_stats.ctx_switches,
                    "interrupts": cpu_stats.interrupts,
                    "soft_interrupts": cpu_stats.soft_interrupts,
                    "syscalls": cpu_stats.syscalls
                },
                "times": {
                    "user": cpu_times.user,
                    "nice": cpu_times.nice,
                    "system": cpu_times.system,
                    "idle": cpu_times.idle,
                    "iowait": getattr(cpu_times, 'iowait', 0),
                    "irq": getattr(cpu_times, 'irq', 0),
                    "softirq": getattr(cpu_times, 'softirq', 0),
                    "steal": getattr(cpu_times, 'steal', 0),
                    "guest": getattr(cpu_times, 'guest', 0),
                    "guest_nice": getattr(cpu_times, 'guest_nice', 0)
                },
                "per_core_usage": cpu_percent_per_core,
                "load_balancing": {
                    "max_core_usage": max(cpu_percent_per_core) if cpu_percent_per_core else 0,
                    "min_core_usage": min(cpu_percent_per_core) if cpu_percent_per_core else 0,
                    "usage_variance": np.var(cpu_percent_per_core) if cpu_percent_per_core else 0,
                    "well_balanced": np.var(cpu_percent_per_core) < 10 if cpu_percent_per_core else True
                }
            }
            
            # Calculs avanc√©s
            if cpu_percent_per_core:
                cpu_data["efficiency_metrics"] = {
                    "utilization_efficiency": min(cpu_percent_per_core) / max(cpu_percent_per_core) if max(cpu_percent_per_core) > 0 else 1.0,
                    "core_saturation_count": sum(1 for usage in cpu_percent_per_core if usage > 80),
                    "idle_core_count": sum(1 for usage in cpu_percent_per_core if usage < 10)
                }
            
            self.history.append(cpu_data)
            return cpu_data
            
        except Exception as e:
            logger.error("Erreur lors de la collecte CPU", error=str(e))
            return {}


class MemoryMetricsCollector:
    """Collecteur sp√©cialis√© pour les m√©triques m√©moire."""
    
    def __init__(self):
        self.history = deque(maxlen=100)
        self.leak_detector = MemoryLeakDetector()
    
    async def collect(self) -> Dict[str, Any]:
        """Collecte d√©taill√©e des m√©triques m√©moire."""
        try:
            # M√©moire virtuelle
            memory = psutil.virtual_memory()
            
            # M√©moire swap
            swap = psutil.swap_memory()
            
            memory_data = {
                "total_bytes": memory.total,
                "available_bytes": memory.available,
                "used_bytes": memory.used,
                "free_bytes": memory.free,
                "usage_percent": memory.percent,
                "buffers_bytes": getattr(memory, 'buffers', 0),
                "cached_bytes": getattr(memory, 'cached', 0),
                "shared_bytes": getattr(memory, 'shared', 0),
                "active_bytes": getattr(memory, 'active', 0),
                "inactive_bytes": getattr(memory, 'inactive', 0),
                "wired_bytes": getattr(memory, 'wired', 0),
                "swap": {
                    "total_bytes": swap.total,
                    "used_bytes": swap.used,
                    "free_bytes": swap.free,
                    "usage_percent": swap.percent,
                    "swap_in_bytes": swap.sin,
                    "swap_out_bytes": swap.sout
                },
                "memory_pressure": self._calculate_memory_pressure(memory, swap),
                "fragmentation_estimate": self._estimate_fragmentation(memory)
            }
            
            # D√©tection de fuites m√©moire
            leak_analysis = await self.leak_detector.analyze(memory_data)
            memory_data["leak_analysis"] = leak_analysis
            
            # Efficacit√© m√©moire
            memory_data["efficiency_metrics"] = {
                "cache_hit_ratio_estimate": self._estimate_cache_efficiency(memory),
                "swap_efficiency": self._calculate_swap_efficiency(swap),
                "memory_fragmentation_percent": self._calculate_fragmentation_percent(memory)
            }
            
            self.history.append(memory_data)
            return memory_data
            
        except Exception as e:
            logger.error("Erreur lors de la collecte m√©moire", error=str(e))
            return {}
    
    def _calculate_memory_pressure(self, memory, swap) -> str:
        """Calcule la pression m√©moire."""
        if memory.percent > 95 or swap.percent > 50:
            return "critical"
        elif memory.percent > 80 or swap.percent > 25:
            return "high"
        elif memory.percent > 60 or swap.percent > 10:
            return "medium"
        else:
            return "low"
    
    def _estimate_fragmentation(self, memory) -> float:
        """Estime la fragmentation m√©moire."""
        # Approximation bas√©e sur la diff√©rence entre libre et disponible
        if memory.total > 0:
            return abs(memory.free - memory.available) / memory.total * 100
        return 0.0
    
    def _estimate_cache_efficiency(self, memory) -> float:
        """Estime l'efficacit√© du cache."""
        cached = getattr(memory, 'cached', 0)
        if memory.total > 0:
            return cached / memory.total * 100
        return 0.0
    
    def _calculate_swap_efficiency(self, swap) -> float:
        """Calcule l'efficacit√© du swap."""
        if swap.total > 0:
            return (1 - swap.percent / 100) * 100
        return 100.0
    
    def _calculate_fragmentation_percent(self, memory) -> float:
        """Calcule le pourcentage de fragmentation."""
        # M√©thode simplifi√©e bas√©e sur les buffers et cache
        buffers = getattr(memory, 'buffers', 0)
        cached = getattr(memory, 'cached', 0)
        
        if memory.total > 0:
            fragmented = memory.used - buffers - cached
            return max(0, fragmented / memory.total * 100)
        return 0.0


class DiskMetricsCollector:
    """Collecteur sp√©cialis√© pour les m√©triques disque."""
    
    def __init__(self):
        self.history = deque(maxlen=100)
        self.io_baseline = {}
    
    async def collect(self) -> Dict[str, Any]:
        """Collecte d√©taill√©e des m√©triques disque."""
        try:
            # Utilisation par partition
            partitions = []
            total_usage = {"total": 0, "used": 0, "free": 0}
            
            for partition in psutil.disk_partitions():
                try:
                    usage = psutil.disk_usage(partition.mountpoint)
                    partition_info = {
                        "device": partition.device,
                        "mountpoint": partition.mountpoint,
                        "filesystem": partition.fstype,
                        "total_bytes": usage.total,
                        "used_bytes": usage.used,
                        "free_bytes": usage.free,
                        "usage_percent": (usage.used / usage.total * 100) if usage.total > 0 else 0,
                        "mount_options": getattr(partition, 'opts', '')
                    }
                    partitions.append(partition_info)
                    
                    total_usage["total"] += usage.total
                    total_usage["used"] += usage.used
                    total_usage["free"] += usage.free
                    
                except (PermissionError, FileNotFoundError):
                    continue
            
            # I/O disque global
            try:
                disk_io = psutil.disk_io_counters()
                io_data = {
                    "read_count": disk_io.read_count,
                    "write_count": disk_io.write_count,
                    "read_bytes": disk_io.read_bytes,
                    "write_bytes": disk_io.write_bytes,
                    "read_time_ms": disk_io.read_time,
                    "write_time_ms": disk_io.write_time,
                    "busy_time_ms": getattr(disk_io, 'busy_time', 0),
                    "read_merged_count": getattr(disk_io, 'read_merged_count', 0),
                    "write_merged_count": getattr(disk_io, 'write_merged_count', 0)
                } if disk_io else {}
            except Exception:
                io_data = {}
            
            # I/O par disque
            try:
                per_disk_io = psutil.disk_io_counters(perdisk=True)
                io_per_disk = {}
                for disk, counters in (per_disk_io or {}).items():
                    io_per_disk[disk] = {
                        "read_count": counters.read_count,
                        "write_count": counters.write_count,
                        "read_bytes": counters.read_bytes,
                        "write_bytes": counters.write_bytes,
                        "read_time_ms": counters.read_time,
                        "write_time_ms": counters.write_time,
                        "iops": (counters.read_count + counters.write_count),
                        "throughput_mbps": (counters.read_bytes + counters.write_bytes) / (1024 * 1024)
                    }
            except Exception:
                io_per_disk = {}
            
            disk_data = {
                "partitions": partitions,
                "total_usage": {
                    **total_usage,
                    "usage_percent": (total_usage["used"] / total_usage["total"] * 100) if total_usage["total"] > 0 else 0
                },
                "io_global": io_data,
                "io_per_disk": io_per_disk,
                "performance_metrics": self._calculate_disk_performance(io_data, io_per_disk),
                "health_indicators": self._assess_disk_health(partitions, io_data)
            }
            
            self.history.append(disk_data)
            return disk_data
            
        except Exception as e:
            logger.error("Erreur lors de la collecte disque", error=str(e))
            return {}
    
    def _calculate_disk_performance(self, io_data: Dict, io_per_disk: Dict) -> Dict[str, Any]:
        """Calcule les m√©triques de performance disque."""
        performance = {}
        
        if io_data:
            total_ops = io_data.get("read_count", 0) + io_data.get("write_count", 0)
            total_time = io_data.get("read_time_ms", 0) + io_data.get("write_time_ms", 0)
            
            performance["total_iops"] = total_ops
            performance["average_latency_ms"] = (total_time / total_ops) if total_ops > 0 else 0
            performance["read_write_ratio"] = (
                io_data.get("read_count", 0) / io_data.get("write_count", 1)
                if io_data.get("write_count", 0) > 0 else 0
            )
            performance["throughput_mbps"] = (
                (io_data.get("read_bytes", 0) + io_data.get("write_bytes", 0)) / (1024 * 1024)
            )
        
        return performance
    
    def _assess_disk_health(self, partitions: List[Dict], io_data: Dict) -> Dict[str, Any]:
        """√âvalue la sant√© des disques."""
        health = {
            "overall_status": "healthy",
            "critical_partitions": [],
            "warning_partitions": [],
            "io_pressure": "low"
        }
        
        for partition in partitions:
            usage_percent = partition.get("usage_percent", 0)
            if usage_percent > 95:
                health["critical_partitions"].append(partition["mountpoint"])
                health["overall_status"] = "critical"
            elif usage_percent > 85:
                health["warning_partitions"].append(partition["mountpoint"])
                if health["overall_status"] == "healthy":
                    health["overall_status"] = "warning"
        
        # √âvaluation de la pression I/O
        if io_data:
            total_time = io_data.get("read_time_ms", 0) + io_data.get("write_time_ms", 0)
            if total_time > 10000:  # Plus de 10 secondes
                health["io_pressure"] = "high"
            elif total_time > 5000:  # Plus de 5 secondes
                health["io_pressure"] = "medium"
        
        return health


class NetworkMetricsCollector:
    """Collecteur sp√©cialis√© pour les m√©triques r√©seau."""
    
    def __init__(self):
        self.history = deque(maxlen=100)
        self.baseline_established = False
        self.previous_counters = {}
    
    async def collect(self) -> Dict[str, Any]:
        """Collecte d√©taill√©e des m√©triques r√©seau."""
        try:
            # Statistiques r√©seau globales
            net_io = psutil.net_io_counters()
            
            # Statistiques par interface
            net_io_per_interface = psutil.net_io_counters(pernic=True)
            
            # Connexions r√©seau
            connections = psutil.net_connections()
            
            # Analyse des connexions
            connection_analysis = self._analyze_connections(connections)
            
            # Interfaces r√©seau
            interfaces = []
            interface_stats = {}
            
            for interface, counters in (net_io_per_interface or {}).items():
                interface_data = {
                    "name": interface,
                    "bytes_sent": counters.bytes_sent,
                    "bytes_recv": counters.bytes_recv,
                    "packets_sent": counters.packets_sent,
                    "packets_recv": counters.packets_recv,
                    "errors_in": counters.errin,
                    "errors_out": counters.errout,
                    "drops_in": counters.dropin,
                    "drops_out": counters.dropout,
                    "throughput_mbps": (counters.bytes_sent + counters.bytes_recv) / (1024 * 1024),
                    "error_rate": self._calculate_error_rate(counters),
                    "packet_loss_rate": self._calculate_packet_loss_rate(counters)
                }
                interfaces.append(interface_data)
                interface_stats[interface] = interface_data
            
            network_data = {
                "global_stats": {
                    "bytes_sent": net_io.bytes_sent if net_io else 0,
                    "bytes_recv": net_io.bytes_recv if net_io else 0,
                    "packets_sent": net_io.packets_sent if net_io else 0,
                    "packets_recv": net_io.packets_recv if net_io else 0,
                    "errors_in": net_io.errin if net_io else 0,
                    "errors_out": net_io.errout if net_io else 0,
                    "drops_in": net_io.dropin if net_io else 0,
                    "drops_out": net_io.dropout if net_io else 0
                } if net_io else {},
                "interfaces": interfaces,
                "connections": {
                    "total_count": len(connections),
                    **connection_analysis
                },
                "performance_metrics": self._calculate_network_performance(net_io, interface_stats),
                "quality_metrics": self._assess_network_quality(interfaces, connection_analysis)
            }
            
            self.history.append(network_data)
            return network_data
            
        except Exception as e:
            logger.error("Erreur lors de la collecte r√©seau", error=str(e))
            return {}
    
    def _analyze_connections(self, connections: List) -> Dict[str, Any]:
        """Analyse d√©taill√©e des connexions r√©seau."""
        analysis = {
            "by_status": defaultdict(int),
            "by_family": defaultdict(int),
            "by_type": defaultdict(int),
            "by_local_port": defaultdict(int),
            "listening_ports": [],
            "established_count": 0,
            "time_wait_count": 0
        }
        
        for conn in connections:
            analysis["by_status"][conn.status] += 1
            analysis["by_family"][str(conn.family)] += 1
            analysis["by_type"][str(conn.type)] += 1
            
            if conn.status == "ESTABLISHED":
                analysis["established_count"] += 1
            elif conn.status == "TIME_WAIT":
                analysis["time_wait_count"] += 1
            elif conn.status == "LISTEN":
                if conn.laddr:
                    analysis["listening_ports"].append(conn.laddr.port)
                    analysis["by_local_port"][conn.laddr.port] += 1
        
        # Conversion en dict normal pour s√©rialisation
        analysis["by_status"] = dict(analysis["by_status"])
        analysis["by_family"] = dict(analysis["by_family"])
        analysis["by_type"] = dict(analysis["by_type"])
        analysis["by_local_port"] = dict(analysis["by_local_port"])
        
        return analysis
    
    def _calculate_error_rate(self, counters) -> float:
        """Calcule le taux d'erreur."""
        total_packets = counters.packets_sent + counters.packets_recv
        total_errors = counters.errin + counters.errout
        
        if total_packets > 0:
            return (total_errors / total_packets) * 100
        return 0.0
    
    def _calculate_packet_loss_rate(self, counters) -> float:
        """Calcule le taux de perte de paquets."""
        total_packets = counters.packets_sent + counters.packets_recv
        total_drops = counters.dropin + counters.dropout
        
        if total_packets > 0:
            return (total_drops / total_packets) * 100
        return 0.0
    
    def _calculate_network_performance(self, net_io, interface_stats: Dict) -> Dict[str, Any]:
        """Calcule les m√©triques de performance r√©seau."""
        performance = {}
        
        if net_io:
            total_throughput = (net_io.bytes_sent + net_io.bytes_recv) / (1024 * 1024)  # MB
            performance["total_throughput_mbps"] = total_throughput
            performance["upload_download_ratio"] = (
                net_io.bytes_sent / net_io.bytes_recv if net_io.bytes_recv > 0 else 0
            )
        
        # Performance par interface
        if interface_stats:
            performance["interface_performance"] = {}
            for interface, stats in interface_stats.items():
                performance["interface_performance"][interface] = {
                    "throughput_mbps": stats["throughput_mbps"],
                    "error_rate": stats["error_rate"],
                    "packet_loss_rate": stats["packet_loss_rate"]
                }
        
        return performance
    
    def _assess_network_quality(self, interfaces: List[Dict], connection_analysis: Dict) -> Dict[str, Any]:
        """√âvalue la qualit√© du r√©seau."""
        quality = {
            "overall_health": "good",
            "issues": [],
            "recommendations": []
        }
        
        # V√©rification des erreurs par interface
        for interface in interfaces:
            if interface["error_rate"] > 1:  # Plus de 1% d'erreurs
                quality["issues"].append(f"Taux d'erreur √©lev√© sur {interface['name']}: {interface['error_rate']:.2f}%")
                quality["overall_health"] = "degraded"
            
            if interface["packet_loss_rate"] > 0.5:  # Plus de 0.5% de perte
                quality["issues"].append(f"Perte de paquets sur {interface['name']}: {interface['packet_loss_rate']:.2f}%")
                quality["overall_health"] = "degraded"
        
        # V√©rification des connexions TIME_WAIT
        if connection_analysis.get("time_wait_count", 0) > 1000:
            quality["issues"].append(f"Nombreuses connexions TIME_WAIT: {connection_analysis['time_wait_count']}")
            quality["recommendations"].append("Ajuster les param√®tres TCP pour r√©duire TIME_WAIT")
        
        return quality


class MemoryLeakDetector:
    """D√©tecteur de fuites m√©moire avanc√©."""
    
    def __init__(self):
        self.memory_trend = deque(maxlen=50)
        self.leak_threshold = 0.1  # 0.1% d'augmentation constante
    
    async def analyze(self, memory_data: Dict[str, Any]) -> Dict[str, Any]:
        """Analyse les tendances m√©moire pour d√©tecter les fuites."""
        
        current_usage = memory_data.get("usage_percent", 0)
        self.memory_trend.append(current_usage)
        
        analysis = {
            "leak_suspected": False,
            "confidence": 0.0,
            "trend": "stable",
            "growth_rate_percent_per_minute": 0.0,
            "recommendation": "none"
        }
        
        if len(self.memory_trend) < 10:
            return analysis
        
        # Calcul de la tendance
        x = np.arange(len(self.memory_trend))
        y = np.array(self.memory_trend)
        
        try:
            # R√©gression lin√©aire pour d√©tecter la tendance
            coeffs = np.polyfit(x, y, 1)
            slope = coeffs[0]
            
            analysis["growth_rate_percent_per_minute"] = slope * 60  # Extrapolation par minute
            
            if slope > self.leak_threshold:
                analysis["leak_suspected"] = True
                analysis["trend"] = "increasing"
                analysis["confidence"] = min(1.0, slope / (self.leak_threshold * 10))
                analysis["recommendation"] = "investigate_memory_usage"
            elif slope < -self.leak_threshold:
                analysis["trend"] = "decreasing"
            else:
                analysis["trend"] = "stable"
                
        except Exception as e:
            logger.error("Erreur lors de l'analyse de fuite m√©moire", error=str(e))
        
        return analysis


class SystemPerformanceCollector(BaseCollector):
    """
    Collecteur de performance syst√®me avec ML et analytics avanc√©s.
    
    Fonctionnalit√©s:
    - Monitoring CPU, m√©moire, disque, r√©seau en temps r√©el
    - D√©tection d'anomalies par Machine Learning (Isolation Forest)
    - Pr√©diction de tendances avec r√©gression temporelle
    - Alerting intelligent avec seuils adaptatifs
    - Corr√©lation cross-m√©trique pour diagnostic
    - Optimisation automatique des ressources
    """
    
    def __init__(self, config: TenantConfig):
        super().__init__(config)
        
        # Configuration ML
        self.ml_enabled = config.performance.get("ml_anomaly_detection", True)
        self.prediction_horizon = config.performance.get("prediction_horizon_minutes", 30)
        
        # Mod√®les ML
        if self.ml_enabled:
            self.anomaly_detector = IsolationForest(
                contamination=0.1,
                random_state=42,
                n_estimators=100
            )
            self.trend_predictors = {}
            self.scaler = StandardScaler()
        
        # Cache pour donn√©es historiques
        self.historical_data = defaultdict(lambda: deque(maxlen=1000))
        self.anomaly_history = deque(maxlen=100)
        
        # M√©triques sp√©cialis√©es
        self.cpu_metrics = CPUMetricsCollector()
        self.memory_metrics = MemoryMetricsCollector()
        self.disk_metrics = DiskMetricsCollector()
        self.network_metrics = NetworkMetricsCollector()
        
        logger.info(
            "Collecteur de performance syst√®me initialis√©",
            tenant_id=config.tenant_id,
            ml_enabled=self.ml_enabled,
            prediction_horizon=self.prediction_horizon
        )
        self.anomaly_detector = PerformanceAnomalyDetector()
    
    async def collect(self) -> Dict[str, Any]:
        """
        Collecte ultra-avanc√©e des m√©triques syst√®me avec ML et analytics.
        
        Fonctionnalit√©s:
        - Collecte multi-m√©trique en parall√®le
        - D√©tection d'anomalies en temps r√©el
        - Pr√©dictions de tendances
        - Corr√©lation cross-m√©trique
        - Optimisation adaptative
        """
        collection_start = time.time()
        
        try:
            # Collecte parall√®le des m√©triques sp√©cialis√©es
            tasks = [
                self.cpu_metrics.collect(),
                self.memory_metrics.collect(),
                self.disk_metrics.collect(),
                self.network_metrics.collect()
            ]
            
            cpu_data, memory_data, disk_data, network_data = await asyncio.gather(*tasks)
            
            # M√©triques syst√®me globales
            system_data = await self._collect_system_globals()
            
            # Assemblage des donn√©es
            raw_metrics = {
                "timestamp": time.time(),
                "tenant_id": self.config.tenant_id,
                "collector_id": self.collector_id,
                "cpu": cpu_data,
                "memory": memory_data,
                "disk": disk_data,
                "network": network_data,
                "system": system_data
            }
            
            # Enrichissement avec ML et analytics
            enriched_metrics = await self._enrich_with_analytics(raw_metrics)
            
            # D√©tection d'anomalies
            anomaly_results = await self._detect_anomalies(enriched_metrics)
            enriched_metrics["anomalies"] = anomaly_results
            
            # Pr√©dictions de tendances
            if self.ml_enabled:
                predictions = await self._generate_predictions(enriched_metrics)
                enriched_metrics["predictions"] = predictions
            
            # Calcul du score de sant√© global
            health_score = await self._calculate_health_score(enriched_metrics)
            enriched_metrics["health_score"] = health_score
            
            # Recommandations d'optimisation
            recommendations = await self._generate_optimization_recommendations(enriched_metrics)
            enriched_metrics["recommendations"] = recommendations
            
            # Mise √† jour de l'historique
            self._update_historical_data(enriched_metrics)
            
            # M√©triques de collecte
            collection_duration = time.time() - collection_start
            enriched_metrics["collection_metadata"] = {
                "duration_seconds": collection_duration,
                "data_quality_score": self._assess_data_quality(enriched_metrics),
                "completeness_percent": self._calculate_completeness(enriched_metrics)
            }
            
            logger.debug(
                "Collecte de performance syst√®me termin√©e",
                tenant_id=self.config.tenant_id,
                duration=collection_duration,
                health_score=health_score,
                anomalies_detected=len(anomaly_results.get("detected_anomalies", []))
            )
            
            return enriched_metrics
            
        except Exception as e:
            logger.error(
                "Erreur lors de la collecte syst√®me",
                tenant_id=self.config.tenant_id,
                error=str(e),
                traceback=traceback.format_exc()
            )
            
            # Retour de m√©triques minimales en cas d'erreur
            return {
                "timestamp": time.time(),
                "tenant_id": self.config.tenant_id,
                "error": str(e),
                "collection_failed": True,
                "basic_metrics": await self._collect_basic_fallback_metrics()
            }
    
    async def _collect_system_globals(self) -> Dict[str, Any]:
        """Collecte les m√©triques syst√®me globales."""
        try:
            # Load average
            try:
                load_avg = psutil.getloadavg()
            except AttributeError:
                load_avg = [0.0, 0.0, 0.0]
            
            # Informations processus
            process_count = len(psutil.pids())
            
            # Temp√©rature syst√®me
            temperature_data = await self._collect_temperature_data()
            
            # Informations de boot
            boot_time = psutil.boot_time()
            uptime = time.time() - boot_time
            
            # Utilisateurs connect√©s
            try:
                users = psutil.users()
                user_count = len(users)
                unique_users = len(set(user.name for user in users))
            except:
                user_count = 0
                unique_users = 0
            
            return {
                "load_average": {
                    "1min": load_avg[0],
                    "5min": load_avg[1],
                    "15min": load_avg[2]
                },
                "processes": {
                    "total_count": process_count,
                    "running": len([p for p in psutil.process_iter(['status']) if p.info['status'] == psutil.STATUS_RUNNING]),
                    "sleeping": len([p for p in psutil.process_iter(['status']) if p.info['status'] == psutil.STATUS_SLEEPING]),
                    "zombie": len([p for p in psutil.process_iter(['status']) if p.info['status'] == psutil.STATUS_ZOMBIE])
                },
                "system": {
                    "boot_time": boot_time,
                    "uptime_seconds": uptime,
                    "uptime_hours": uptime / 3600,
                    "platform": platform.system(),
                    "platform_release": platform.release(),
                    "hostname": socket.gethostname()
                },
                "users": {
                    "active_sessions": user_count,
                    "unique_users": unique_users
                },
                "temperature": temperature_data
            }
            
        except Exception as e:
            logger.error("Erreur collecte syst√®me globale", error=str(e))
            return {}
    
    async def _collect_temperature_data(self) -> Dict[str, Any]:
        """Collecte les donn√©es de temp√©rature du syst√®me."""
        try:
            sensors = psutil.sensors_temperatures()
            if not sensors:
                return {"available": False}
            
            temperature_data = {"available": True, "sensors": {}}
            
            for sensor_name, entries in sensors.items():
                sensor_temps = []
                for entry in entries:
                    if entry.current:
                        sensor_temps.append({
                            "current": entry.current,
                            "high": entry.high,
                            "critical": entry.critical,
                            "label": entry.label
                        })
                
                if sensor_temps:
                    temperature_data["sensors"][sensor_name] = {
                        "readings": sensor_temps,
                        "average": statistics.mean([t["current"] for t in sensor_temps]),
                        "max": max([t["current"] for t in sensor_temps]),
                        "critical_count": sum(1 for t in sensor_temps if t["critical"] and t["current"] > t["critical"])
                    }
            
            # Temp√©rature moyenne globale
            all_temps = []
            for sensor_data in temperature_data["sensors"].values():
                all_temps.extend([t["current"] for t in sensor_data["readings"]])
            
            if all_temps:
                temperature_data["global"] = {
                    "average": statistics.mean(all_temps),
                    "max": max(all_temps),
                    "min": min(all_temps),
                    "critical_threshold_exceeded": any(
                        temp > 80 for temp in all_temps  # Seuil critique g√©n√©rique
                    )
                }
            
            return temperature_data
            
        except Exception as e:
            logger.error("Erreur collecte temp√©rature", error=str(e))
            return {"available": False, "error": str(e)}
    
    async def _enrich_with_analytics(self, raw_metrics: Dict[str, Any]) -> Dict[str, Any]:
        """Enrichit les m√©triques avec des analytics avanc√©s."""
        try:
            enriched = raw_metrics.copy()
            
            # Calculs de tendances
            if len(self.historical_data["cpu_percent"]) > 10:
                cpu_trend = self._calculate_trend(list(self.historical_data["cpu_percent"]))
                enriched["trends"] = {"cpu_percent": cpu_trend}
            
            # Corr√©lations entre m√©triques
            correlations = await self._calculate_metric_correlations()
            enriched["correlations"] = correlations
            
            # Scores d'efficacit√©
            efficiency_scores = await self._calculate_efficiency_scores(raw_metrics)
            enriched["efficiency"] = efficiency_scores
            
            # Patterns d'usage
            usage_patterns = await self._analyze_usage_patterns(raw_metrics)
            enriched["usage_patterns"] = usage_patterns
            
            return enriched
            
        except Exception as e:
            logger.error("Erreur enrichissement analytics", error=str(e))
            return raw_metrics
    
    async def _detect_anomalies(self, metrics: Dict[str, Any]) -> Dict[str, Any]:
        """D√©tecte les anomalies dans les m√©triques."""
        try:
            anomalies = {
                "detected_anomalies": [],
                "anomaly_scores": {},
                "detection_method": "isolation_forest",
                "threshold": 0.1
            }
            
            if not self.ml_enabled:
                return anomalies
            
            # Pr√©paration des donn√©es pour ML
            feature_vector = self._extract_features_for_ml(metrics)
            
            if len(self.historical_data["feature_vectors"]) >= 50:
                # D√©tection avec mod√®le entra√Æn√©
                anomaly_score = self.anomaly_detector.decision_function([feature_vector])[0]
                is_anomaly = self.anomaly_detector.predict([feature_vector])[0] == -1
                
                anomalies["anomaly_scores"]["global"] = float(anomaly_score)
                
                if is_anomaly:
                    anomaly_detail = {
                        "timestamp": metrics["timestamp"],
                        "type": "statistical_anomaly",
                        "score": float(anomaly_score),
                        "affected_metrics": self._identify_anomalous_metrics(feature_vector),
                        "severity": self._classify_anomaly_severity(anomaly_score),
                        "context": self._generate_anomaly_context(metrics)
                    }
                    anomalies["detected_anomalies"].append(anomaly_detail)
                    
                    # Log de l'anomalie
                    logger.warning(
                        "Anomalie syst√®me d√©tect√©e",
                        tenant_id=self.config.tenant_id,
                        score=anomaly_score,
                        severity=anomaly_detail["severity"]
                    )
            
            # D√©tection par seuils adaptatifs
            threshold_anomalies = await self._detect_threshold_anomalies(metrics)
            anomalies["detected_anomalies"].extend(threshold_anomalies)
            
            return anomalies
            
        except Exception as e:
            logger.error("Erreur d√©tection anomalies", error=str(e))
            return {"detected_anomalies": [], "error": str(e)}
    
    async def _generate_predictions(self, metrics: Dict[str, Any]) -> Dict[str, Any]:
        """G√©n√®re des pr√©dictions de tendances."""
        try:
            predictions = {
                "horizon_minutes": self.prediction_horizon,
                "generated_at": time.time(),
                "forecasts": {}
            }
            
            # Pr√©dictions CPU
            if len(self.historical_data["cpu_percent"]) >= 20:
                cpu_forecast = self._predict_metric_trend(
                    list(self.historical_data["cpu_percent"]),
                    self.prediction_horizon
                )
                predictions["forecasts"]["cpu_percent"] = cpu_forecast
            
            # Pr√©dictions m√©moire
            if len(self.historical_data["memory_percent"]) >= 20:
                memory_forecast = self._predict_metric_trend(
                    list(self.historical_data["memory_percent"]),
                    self.prediction_horizon
                )
                predictions["forecasts"]["memory_percent"] = memory_forecast
            
            # Pr√©dictions disque
            if len(self.historical_data["disk_percent"]) >= 20:
                disk_forecast = self._predict_metric_trend(
                    list(self.historical_data["disk_percent"]),
                    self.prediction_horizon
                )
                predictions["forecasts"]["disk_percent"] = disk_forecast
            
            # Alertes pr√©dictives
            predictive_alerts = await self._generate_predictive_alerts(predictions)
            predictions["predictive_alerts"] = predictive_alerts
            
            return predictions
            
        except Exception as e:
            logger.error("Erreur g√©n√©ration pr√©dictions", error=str(e))
            return {"error": str(e)}
    
    async def _calculate_health_score(self, metrics: Dict[str, Any]) -> float:
        """Calcule un score de sant√© global du syst√®me (0-100)."""
        try:
            scores = []
            
            # Score CPU (invers√© car plus c'est bas, mieux c'est)
            cpu_percent = metrics.get("cpu", {}).get("usage_percent", 0)
            cpu_score = max(0, 100 - cpu_percent)
            scores.append(("cpu", cpu_score, 0.3))  # Poids 30%
            
            # Score m√©moire
            memory_percent = metrics.get("memory", {}).get("usage_percent", 0)
            memory_score = max(0, 100 - memory_percent)
            scores.append(("memory", memory_score, 0.3))  # Poids 30%
            
            # Score disque (moyenne des partitions)
            disk_data = metrics.get("disk", {})
            if disk_data and "usage_by_partition" in disk_data:
                disk_percentages = [
                    partition.get("percent", 0) 
                    for partition in disk_data["usage_by_partition"].values()
                ]
                avg_disk_percent = statistics.mean(disk_percentages) if disk_percentages else 0
                disk_score = max(0, 100 - avg_disk_percent)
            else:
                disk_score = 100
            scores.append(("disk", disk_score, 0.2))  # Poids 20%
            
            # Score anomalies
            anomalies = metrics.get("anomalies", {})
            anomaly_count = len(anomalies.get("detected_anomalies", []))
            anomaly_score = max(0, 100 - (anomaly_count * 10))  # -10 points par anomalie
            scores.append(("anomalies", anomaly_score, 0.1))  # Poids 10%
            
            # Score temp√©rature
            temp_data = metrics.get("system", {}).get("temperature", {})
            if temp_data.get("available") and "global" in temp_data:
                temp_avg = temp_data["global"].get("average", 0)
                if temp_avg > 80:
                    temp_score = 0
                elif temp_avg > 70:
                    temp_score = 50
                else:
                    temp_score = 100
            else:
                temp_score = 100
            scores.append(("temperature", temp_score, 0.1))  # Poids 10%
            
            # Calcul du score pond√©r√©
            weighted_score = sum(score * weight for _, score, weight in scores)
            
            # Normalisation finale
            final_score = max(0, min(100, weighted_score))
            
            logger.debug(
                "Score de sant√© calcul√©",
                tenant_id=self.config.tenant_id,
                final_score=final_score,
                component_scores={name: score for name, score, _ in scores}
            )
            
            return final_score
            
        except Exception as e:
            logger.error("Erreur calcul score sant√©", error=str(e))
            return 50.0  # Score neutre en cas d'erreur
    
    async def _generate_optimization_recommendations(self, metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
        """G√©n√®re des recommandations d'optimisation bas√©es sur les m√©triques."""
        try:
            recommendations = []
            
            # Analyse CPU
            cpu_data = metrics.get("cpu", {})
            cpu_percent = cpu_data.get("usage_percent", 0)
            
            if cpu_percent > 80:
                recommendations.append({
                    "category": "cpu",
                    "priority": "high" if cpu_percent > 95 else "medium",
                    "title": "Optimisation CPU requise",
                    "description": f"Utilisation CPU √©lev√©e ({cpu_percent:.1f}%)",
                    "actions": [
                        "Identifier les processus consommateurs",
                        "Optimiser les algorithmes critiques",
                        "Consid√©rer l'ajout de ressources CPU",
                        "Impl√©menter la mise √† l'√©chelle horizontale"
                    ],
                    "estimated_impact": "high"
                })
            
            # Analyse m√©moire
            memory_data = metrics.get("memory", {})
            memory_percent = memory_data.get("usage_percent", 0)
            
            if memory_percent > 80:
                recommendations.append({
                    "category": "memory",
                    "priority": "high" if memory_percent > 95 else "medium",
                    "title": "Optimisation m√©moire requise",
                    "description": f"Utilisation m√©moire √©lev√©e ({memory_percent:.1f}%)",
                    "actions": [
                        "Analyser les fuites m√©moire potentielles",
                        "Optimiser les caches et buffers",
                        "Impl√©menter la pagination intelligente",
                        "Augmenter la RAM disponible"
                    ],
                    "estimated_impact": "high"
                })
            
            # Analyse disque
            disk_data = metrics.get("disk", {})
            if "usage_by_partition" in disk_data:
                for partition, usage in disk_data["usage_by_partition"].items():
                    if usage.get("percent", 0) > 85:
                        recommendations.append({
                            "category": "disk",
                            "priority": "high" if usage["percent"] > 95 else "medium",
                            "title": f"Espace disque faible sur {partition}",
                            "description": f"Partition {partition} √† {usage['percent']:.1f}%",
                            "actions": [
                                "Nettoyer les fichiers temporaires",
                                "Archiver les anciens logs",
                                "Impl√©menter la rotation des donn√©es",
                                "√âtendre l'espace de stockage"
                            ],
                            "estimated_impact": "medium"
                        })
            
            # Analyse des anomalies
            anomalies = metrics.get("anomalies", {})
            if anomalies.get("detected_anomalies"):
                recommendations.append({
                    "category": "anomalies",
                    "priority": "high",
                    "title": "Anomalies syst√®me d√©tect√©es",
                    "description": f"{len(anomalies['detected_anomalies'])} anomalie(s) d√©tect√©e(s)",
                    "actions": [
                        "Investiguer les anomalies d√©tect√©es",
                        "V√©rifier la configuration syst√®me",
                        "Analyser les patterns d'usage",
                        "Ajuster les seuils de monitoring"
                    ],
                    "estimated_impact": "high"
                })
            
            # Recommandations pr√©dictives
            predictions = metrics.get("predictions", {})
            if predictions.get("predictive_alerts"):
                for alert in predictions["predictive_alerts"]:
                    recommendations.append({
                        "category": "predictive",
                        "priority": "medium",
                        "title": f"Risque pr√©dit: {alert['metric']}",
                        "description": f"Seuil critique pr√©vu dans {alert['time_to_threshold']} minutes",
                        "actions": [
                            "Prendre des mesures pr√©ventives",
                            "Pr√©parer la mise √† l'√©chelle",
                            "Alerter les √©quipes concern√©es",
                            "Documenter les patterns observ√©s"
                        ],
                        "estimated_impact": "medium"
                    })
            
            return recommendations
            
        except Exception as e:
            logger.error("Erreur g√©n√©ration recommandations", error=str(e))
            return []
                            'write_time': disk_io.write_time
                        }
                    },
                    'network': {
                        'bytes_sent': network_io.bytes_sent,
                        'bytes_recv': network_io.bytes_recv,
                        'packets_sent': network_io.packets_sent,
                        'packets_recv': network_io.packets_recv,
                        'errin': network_io.errin,
                        'errout': network_io.errout,
                        'dropin': network_io.dropin,
                        'dropout': network_io.dropout,
                        'connections_count': network_connections
                    },
                    'processes': {
                        'count': process_count,
                        'load_average_1m': load_avg[0],
                        'load_average_5m': load_avg[1],
                        'load_average_15m': load_avg[2]
                    },
                    'temperature': temperature,
                    'uptime': time.time() - psutil.boot_time()
                }
            }
            
            # D√©tection d'anomalies
            anomalies = await self.anomaly_detector.detect_anomalies(metrics)
            if anomalies:
                metrics['anomalies'] = anomalies
            
            return metrics
            
        except Exception as e:
            logger.error(f"Erreur collecte m√©triques syst√®me: {str(e)}")
            raise
    
    async def validate_data(self, data: Dict[str, Any]) -> bool:
        """Valide les m√©triques syst√®me collect√©es."""
        try:
            system_perf = data.get('system_performance', {})
            
            # Validation CPU
            cpu_data = system_perf.get('cpu', {})
            if not (0 <= cpu_data.get('percent_total', -1) <= 100):
                return False
            
            # Validation m√©moire
            memory_data = system_perf.get('memory', {})
            if not (0 <= memory_data.get('percent', -1) <= 100):
                return False
            
            # Validation des valeurs critiques
            critical_metrics = [
                'cpu.percent_total',
                'memory.percent',
                'processes.count'
            ]
            
            for metric_path in critical_metrics:
                keys = metric_path.split('.')
                value = system_perf
                for key in keys:
                    value = value.get(key)
                    if value is None:
                        logger.warning(f"M√©trique manquante: {metric_path}")
                        return False
            
            return True
            
        except Exception as e:
            logger.error(f"Erreur validation donn√©es syst√®me: {str(e)}")
            return False
    
    # M√©thodes d'aide pour le SystemPerformanceCollector
    
    def _update_historical_data(self, metrics: Dict[str, Any]) -> None:
        """Met √† jour les donn√©es historiques pour le ML."""
        try:
            # Extraction des m√©triques cl√©s
            cpu_percent = metrics.get("cpu", {}).get("usage_percent", 0)
            memory_percent = metrics.get("memory", {}).get("usage_percent", 0)
            
            # Mise √† jour des s√©ries temporelles
            self.historical_data["cpu_percent"].append(cpu_percent)
            self.historical_data["memory_percent"].append(memory_percent)
            
            # Disque (moyenne des partitions)
            disk_data = metrics.get("disk", {})
            if disk_data and "usage_by_partition" in disk_data:
                disk_percentages = [
                    partition.get("percent", 0) 
                    for partition in disk_data["usage_by_partition"].values()
                ]
                if disk_percentages:
                    avg_disk_percent = statistics.mean(disk_percentages)
                    self.historical_data["disk_percent"].append(avg_disk_percent)
            
            # Vecteur de features pour ML
            if self.ml_enabled:
                feature_vector = self._extract_features_for_ml(metrics)
                self.historical_data["feature_vectors"].append(feature_vector)
                
                # Entra√Ænement p√©riodique du mod√®le
                if len(self.historical_data["feature_vectors"]) >= 100:
                    self._retrain_anomaly_detector()
        
        except Exception as e:
            logger.error("Erreur mise √† jour donn√©es historiques", error=str(e))
    
    def _extract_features_for_ml(self, metrics: Dict[str, Any]) -> List[float]:
        """Extrait un vecteur de features pour le ML."""
        try:
            features = []
            
            # Features CPU
            cpu_data = metrics.get("cpu", {})
            features.append(cpu_data.get("usage_percent", 0))
            features.append(len(cpu_data.get("usage_per_core", [])))
            
            # Features m√©moire
            memory_data = metrics.get("memory", {})
            features.append(memory_data.get("usage_percent", 0))
            features.append(memory_data.get("total_bytes", 0) / (1024**3))  # GB
            
            # Features disque
            disk_data = metrics.get("disk", {})
            if disk_data and "usage_by_partition" in disk_data:
                disk_percentages = [
                    partition.get("percent", 0) 
                    for partition in disk_data["usage_by_partition"].values()
                ]
                features.append(statistics.mean(disk_percentages) if disk_percentages else 0)
                features.append(len(disk_percentages))
            else:
                features.extend([0, 0])
            
            # Features r√©seau
            network_data = metrics.get("network", {})
            features.append(network_data.get("bytes_sent_rate", 0))
            features.append(network_data.get("bytes_recv_rate", 0))
            
            # Features syst√®me
            system_data = metrics.get("system", {})
            load_avg = system_data.get("load_average", {})
            features.append(load_avg.get("1min", 0))
            features.append(system_data.get("processes", {}).get("total_count", 0))
            
            return features
        
        except Exception as e:
            logger.error("Erreur extraction features ML", error=str(e))
            return [0.0] * 10  # Vecteur par d√©faut
    
    def _retrain_anomaly_detector(self) -> None:
        """R√©-entra√Æne le d√©tecteur d'anomalies."""
        try:
            if not self.ml_enabled or len(self.historical_data["feature_vectors"]) < 50:
                return
            
            # Pr√©paration des donn√©es
            X = np.array(list(self.historical_data["feature_vectors"]))
            X_scaled = self.scaler.fit_transform(X)
            
            # Entra√Ænement
            self.anomaly_detector.fit(X_scaled)
            
            logger.info(
                "Mod√®le d'anomalie r√©-entra√Æn√©",
                tenant_id=self.config.tenant_id,
                samples=len(X)
            )
        
        except Exception as e:
            logger.error("Erreur r√©-entra√Ænement mod√®le", error=str(e))
    
    def _calculate_trend(self, data_points: List[float]) -> Dict[str, Any]:
        """Calcule la tendance d'une s√©rie de donn√©es."""
        try:
            if len(data_points) < 3:
                return {"trend": "insufficient_data"}
            
            # R√©gression lin√©aire simple
            x = np.arange(len(data_points))
            y = np.array(data_points)
            
            # Calcul de la pente
            slope = np.polyfit(x, y, 1)[0]
            
            # Classification de la tendance
            if abs(slope) < 0.1:
                trend_type = "stable"
            elif slope > 0:
                trend_type = "increasing"
            else:
                trend_type = "decreasing"
            
            # Calcul de la corr√©lation
            correlation = np.corrcoef(x, y)[0, 1] if len(x) > 1 else 0
            
            return {
                "trend": trend_type,
                "slope": float(slope),
                "correlation": float(correlation),
                "confidence": abs(correlation)
            }
        
        except Exception as e:
            logger.error("Erreur calcul tendance", error=str(e))
            return {"trend": "error", "error": str(e)}
    
    async def _calculate_metric_correlations(self) -> Dict[str, Any]:
        """Calcule les corr√©lations entre m√©triques."""
        try:
            correlations = {}
            
            if len(self.historical_data["cpu_percent"]) < 10:
                return correlations
            
            # Corr√©lation CPU-M√©moire
            cpu_data = list(self.historical_data["cpu_percent"])[-50:]
            memory_data = list(self.historical_data["memory_percent"])[-50:]
            
            if len(cpu_data) == len(memory_data) and len(cpu_data) > 1:
                cpu_memory_corr = np.corrcoef(cpu_data, memory_data)[0, 1]
                correlations["cpu_memory"] = float(cpu_memory_corr)
            
            return correlations
        
        except Exception as e:
            logger.error("Erreur calcul corr√©lations", error=str(e))
            return {}
    
    async def _calculate_efficiency_scores(self, metrics: Dict[str, Any]) -> Dict[str, Any]:
        """Calcule les scores d'efficacit√©."""
        try:
            efficiency = {}
            
            # Efficacit√© CPU
            cpu_data = metrics.get("cpu", {})
            if "load_balancing" in cpu_data:
                load_balance = cpu_data["load_balancing"]
                efficiency["cpu_load_balancing"] = 100 - load_balance.get("usage_variance", 0)
            
            # Efficacit√© m√©moire
            memory_data = metrics.get("memory", {})
            if "efficiency_metrics" in memory_data:
                efficiency.update(memory_data["efficiency_metrics"])
            
            return efficiency
        
        except Exception as e:
            logger.error("Erreur calcul efficacit√©", error=str(e))
            return {}
    
    async def _analyze_usage_patterns(self, metrics: Dict[str, Any]) -> Dict[str, Any]:
        """Analyse les patterns d'usage."""
        try:
            patterns = {}
            
            # Pattern d'heure de pointe
            current_hour = datetime.now().hour
            if current_hour in [9, 10, 11, 14, 15, 16]:
                patterns["time_category"] = "peak_hours"
            elif current_hour in [12, 13]:
                patterns["time_category"] = "lunch_hours"
            elif current_hour < 8 or current_hour > 18:
                patterns["time_category"] = "off_hours"
            else:
                patterns["time_category"] = "normal_hours"
            
            # Pattern de charge
            cpu_percent = metrics.get("cpu", {}).get("usage_percent", 0)
            memory_percent = metrics.get("memory", {}).get("usage_percent", 0)
            
            avg_load = (cpu_percent + memory_percent) / 2
            
            if avg_load > 80:
                patterns["load_category"] = "high_load"
            elif avg_load > 50:
                patterns["load_category"] = "medium_load"
            else:
                patterns["load_category"] = "low_load"
            
            return patterns
        
        except Exception as e:
            logger.error("Erreur analyse patterns", error=str(e))
            return {}
    
    def _identify_anomalous_metrics(self, feature_vector: List[float]) -> List[str]:
        """Identifie quelles m√©triques sont anomales."""
        try:
            # Noms des features dans l'ordre
            feature_names = [
                "cpu_percent", "cpu_core_count", "memory_percent", "memory_total_gb",
                "disk_percent_avg", "disk_partition_count", "network_sent_rate",
                "network_recv_rate", "load_avg_1min", "process_count"
            ]
            
            anomalous_metrics = []
            
            # Seuils empiriques pour identifier les anomalies
            if len(feature_vector) >= len(feature_names):
                if feature_vector[0] > 95:  # CPU
                    anomalous_metrics.append("cpu_percent")
                if feature_vector[2] > 95:  # M√©moire
                    anomalous_metrics.append("memory_percent")
                if feature_vector[4] > 90:  # Disque
                    anomalous_metrics.append("disk_percent")
                if feature_vector[8] > 10:  # Load average
                    anomalous_metrics.append("load_average")
            
            return anomalous_metrics
        
        except Exception as e:
            logger.error("Erreur identification m√©triques anomales", error=str(e))
            return []
    
    def _classify_anomaly_severity(self, anomaly_score: float) -> str:
        """Classifie la s√©v√©rit√© d'une anomalie."""
        # Score d'isolation forest : plus n√©gatif = plus anomal
        if anomaly_score < -0.5:
            return "critical"
        elif anomaly_score < -0.3:
            return "high"
        elif anomaly_score < -0.1:
            return "medium"
        else:
            return "low"
    
    def _generate_anomaly_context(self, metrics: Dict[str, Any]) -> Dict[str, Any]:
        """G√©n√®re le contexte d'une anomalie."""
        try:
            context = {
                "system_load": {
                    "cpu": metrics.get("cpu", {}).get("usage_percent", 0),
                    "memory": metrics.get("memory", {}).get("usage_percent", 0),
                    "disk": "N/A"
                },
                "time_context": {
                    "hour": datetime.now().hour,
                    "day_of_week": datetime.now().strftime("%A"),
                    "timestamp": metrics.get("timestamp", time.time())
                }
            }
            
            # Contexte disque
            disk_data = metrics.get("disk", {})
            if disk_data and "usage_by_partition" in disk_data:
                disk_percentages = [
                    partition.get("percent", 0) 
                    for partition in disk_data["usage_by_partition"].values()
                ]
                if disk_percentages:
                    context["system_load"]["disk"] = statistics.mean(disk_percentages)
            
            return context
        
        except Exception as e:
            logger.error("Erreur g√©n√©ration contexte anomalie", error=str(e))
            return {}
    
    async def _detect_threshold_anomalies(self, metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
        """D√©tecte les anomalies par seuils."""
        try:
            threshold_anomalies = []
            
            # Seuils CPU
            cpu_percent = metrics.get("cpu", {}).get("usage_percent", 0)
            if cpu_percent > 95:
                threshold_anomalies.append({
                    "type": "threshold_anomaly",
                    "metric": "cpu_percent",
                    "value": cpu_percent,
                    "threshold": 95,
                    "severity": "critical",
                    "description": f"Utilisation CPU critique: {cpu_percent:.1f}%"
                })
            
            # Seuils m√©moire
            memory_percent = metrics.get("memory", {}).get("usage_percent", 0)
            if memory_percent > 90:
                threshold_anomalies.append({
                    "type": "threshold_anomaly",
                    "metric": "memory_percent",
                    "value": memory_percent,
                    "threshold": 90,
                    "severity": "high" if memory_percent < 95 else "critical",
                    "description": f"Utilisation m√©moire √©lev√©e: {memory_percent:.1f}%"
                })
            
            return threshold_anomalies
        
        except Exception as e:
            logger.error("Erreur d√©tection seuils", error=str(e))
            return []
    
    def _predict_metric_trend(self, historical_values: List[float], horizon_minutes: int) -> Dict[str, Any]:
        """Pr√©dit la tendance d'une m√©trique."""
        try:
            if len(historical_values) < 10:
                return {"error": "insufficient_data"}
            
            # R√©gression lin√©aire simple pour pr√©diction
            x = np.arange(len(historical_values))
            y = np.array(historical_values)
            
            # Ajustement lin√©aire
            coeffs = np.polyfit(x, y, 1)
            slope, intercept = coeffs
            
            # Pr√©diction future
            future_x = len(historical_values) + horizon_minutes
            predicted_value = slope * future_x + intercept
            
            # Intervalle de confiance basique
            residuals = y - (slope * x + intercept)
            std_error = np.std(residuals)
            
            return {
                "predicted_value": float(predicted_value),
                "confidence_interval": {
                    "lower": float(predicted_value - 1.96 * std_error),
                    "upper": float(predicted_value + 1.96 * std_error)
                },
                "trend_slope": float(slope),
                "trend_direction": "increasing" if slope > 0 else "decreasing" if slope < 0 else "stable"
            }
        
        except Exception as e:
            logger.error("Erreur pr√©diction tendance", error=str(e))
            return {"error": str(e)}
    
    async def _generate_predictive_alerts(self, predictions: Dict[str, Any]) -> List[Dict[str, Any]]:
        """G√©n√®re des alertes pr√©dictives."""
        try:
            predictive_alerts = []
            
            forecasts = predictions.get("forecasts", {})
            
            # Alerte CPU pr√©dictive
            if "cpu_percent" in forecasts:
                cpu_forecast = forecasts["cpu_percent"]
                predicted_cpu = cpu_forecast.get("predicted_value", 0)
                
                if predicted_cpu > 85:
                    time_to_threshold = self._calculate_time_to_threshold(
                        list(self.historical_data["cpu_percent"]),
                        85,
                        predictions["horizon_minutes"]
                    )
                    
                    predictive_alerts.append({
                        "metric": "cpu_percent",
                        "predicted_value": predicted_cpu,
                        "threshold": 85,
                        "time_to_threshold": time_to_threshold,
                        "severity": "warning",
                        "action_required": "Pr√©parer la mise √† l'√©chelle CPU"
                    })
            
            # Alerte m√©moire pr√©dictive
            if "memory_percent" in forecasts:
                memory_forecast = forecasts["memory_percent"]
                predicted_memory = memory_forecast.get("predicted_value", 0)
                
                if predicted_memory > 85:
                    time_to_threshold = self._calculate_time_to_threshold(
                        list(self.historical_data["memory_percent"]),
                        85,
                        predictions["horizon_minutes"]
                    )
                    
                    predictive_alerts.append({
                        "metric": "memory_percent",
                        "predicted_value": predicted_memory,
                        "threshold": 85,
                        "time_to_threshold": time_to_threshold,
                        "severity": "warning",
                        "action_required": "Optimiser l'utilisation m√©moire"
                    })
            
            return predictive_alerts
        
        except Exception as e:
            logger.error("Erreur alertes pr√©dictives", error=str(e))
            return []
    
    def _calculate_time_to_threshold(self, values: List[float], threshold: float, horizon: int) -> int:
        """Calcule le temps avant d'atteindre un seuil."""
        try:
            if len(values) < 5:
                return horizon
            
            # Tendance r√©cente
            recent_values = values[-10:]
            if len(recent_values) < 2:
                return horizon
            
            # Calcul de la pente
            x = np.arange(len(recent_values))
            slope = np.polyfit(x, recent_values, 1)[0]
            
            if slope <= 0:
                return horizon  # Pas d'augmentation
            
            # Extrapolation
            current_value = recent_values[-1]
            if current_value >= threshold:
                return 0
            
            time_to_threshold = (threshold - current_value) / slope
            return min(int(time_to_threshold), horizon)
        
        except Exception as e:
            logger.error("Erreur calcul temps au seuil", error=str(e))
            return horizon
    
    def _assess_data_quality(self, metrics: Dict[str, Any]) -> float:
        """√âvalue la qualit√© des donn√©es collect√©es."""
        try:
            quality_factors = []
            
            # Compl√©tude des donn√©es
            expected_sections = ["cpu", "memory", "disk", "network", "system"]
            present_sections = sum(1 for section in expected_sections if section in metrics)
            completeness = present_sections / len(expected_sections)
            quality_factors.append(completeness)
            
            # Coh√©rence des valeurs
            cpu_percent = metrics.get("cpu", {}).get("usage_percent", 0)
            memory_percent = metrics.get("memory", {}).get("usage_percent", 0)
            
            consistency = 1.0
            if cpu_percent < 0 or cpu_percent > 100:
                consistency -= 0.3
            if memory_percent < 0 or memory_percent > 100:
                consistency -= 0.3
            
            quality_factors.append(max(0, consistency))
            
            # Fra√Æcheur des donn√©es
            timestamp = metrics.get("timestamp", time.time())
            age_seconds = time.time() - timestamp
            freshness = max(0, 1 - (age_seconds / 300))  # D√©grade apr√®s 5 min
            quality_factors.append(freshness)
            
            return statistics.mean(quality_factors) * 100
        
        except Exception as e:
            logger.error("Erreur √©valuation qualit√©", error=str(e))
            return 50.0
    
    def _calculate_completeness(self, metrics: Dict[str, Any]) -> float:
        """Calcule le pourcentage de compl√©tude des m√©triques."""
        try:
            total_fields = 0
            present_fields = 0
            
            # D√©finition des champs attendus
            expected_structure = {
                "cpu": ["usage_percent", "usage_per_core", "core_count"],
                "memory": ["usage_percent", "total_bytes", "available_bytes"],
                "disk": ["usage_by_partition"],
                "network": ["bytes_sent_rate", "bytes_recv_rate"],
                "system": ["load_average", "processes"]
            }
            
            for section, fields in expected_structure.items():
                total_fields += len(fields)
                section_data = metrics.get(section, {})
                
                for field in fields:
                    if field in section_data and section_data[field] is not None:
                        present_fields += 1
            
            return (present_fields / total_fields * 100) if total_fields > 0 else 0
        
        except Exception as e:
            logger.error("Erreur calcul compl√©tude", error=str(e))
            return 0.0
    
    async def _collect_basic_fallback_metrics(self) -> Dict[str, Any]:
        """Collecte des m√©triques de base en cas d'erreur."""
        try:
            return {
                "cpu_percent": psutil.cpu_percent(),
                "memory_percent": psutil.virtual_memory().percent,
                "disk_percent": psutil.disk_usage('/').percent,
                "timestamp": time.time(),
                "fallback_mode": True
            }
        except Exception as e:
            logger.error("Erreur m√©triques fallback", error=str(e))
            return {"error": "complete_failure", "timestamp": time.time()}


class DatabasePerformanceCollector(BaseCollector):
    """Collecteur de performances des bases de donn√©es."""
    
    def __init__(self, config: CollectorConfig):
        super().__init__(config)
        self.db_connections = {}
        self.query_history = []
        
    async def collect(self) -> Dict[str, Any]:
        """Collecte les m√©triques de toutes les bases de donn√©es."""
        metrics = {}
        
        # PostgreSQL metrics
        postgres_metrics = await self._collect_postgres_metrics()
        if postgres_metrics:
            metrics['postgresql'] = postgres_metrics
        
        # Redis metrics
        redis_metrics = await self._collect_redis_metrics()
        if redis_metrics:
            metrics['redis'] = redis_metrics
        
        # MongoDB metrics
        mongo_metrics = await self._collect_mongo_metrics()
        if mongo_metrics:
            metrics['mongodb'] = mongo_metrics
        
        return {'database_performance': metrics}
    
    async def _collect_postgres_metrics(self) -> Optional[Dict[str, Any]]:
        """Collecte les m√©triques PostgreSQL."""
        try:
            # Configuration de connexion depuis l'environnement
            db_url = self.config.tags.get('postgres_url', 'postgresql://localhost:5432/postgres')
            
            conn = await asyncpg.connect(db_url)
            
            # M√©triques de base
            stats_query = """
                SELECT 
                    count(*) as total_connections,
                    count(*) FILTER (WHERE state = 'active') as active_connections,
                    count(*) FILTER (WHERE state = 'idle') as idle_connections,
                    count(*) FILTER (WHERE state = 'idle in transaction') as idle_in_transaction
                FROM pg_stat_activity;
            """
            
            connection_stats = await conn.fetchrow(stats_query)
            
            # M√©triques de performance des requ√™tes
            query_stats_query = """
                SELECT 
                    datname,
                    numbackends,
                    xact_commit,
                    xact_rollback,
                    blks_read,
                    blks_hit,
                    tup_returned,
                    tup_fetched,
                    tup_inserted,
                    tup_updated,
                    tup_deleted
                FROM pg_stat_database 
                WHERE datname NOT IN ('template0', 'template1', 'postgres');
            """
            
            db_stats = await conn.fetch(query_stats_query)
            
            # M√©triques de cache
            cache_hit_ratio = await conn.fetchval("""
                SELECT 
                    round(
                        sum(blks_hit) * 100.0 / nullif(sum(blks_hit + blks_read), 0), 2
                    ) as cache_hit_ratio
                FROM pg_stat_database;
            """)
            
            # M√©triques des tables les plus utilis√©es
            table_stats_query = """
                SELECT 
                    schemaname,
                    tablename,
                    seq_scan,
                    seq_tup_read,
                    idx_scan,
                    idx_tup_fetch,
                    n_tup_ins,
                    n_tup_upd,
                    n_tup_del
                FROM pg_stat_user_tables
                ORDER BY seq_scan + idx_scan DESC
                LIMIT 10;
            """
            
            table_stats = await conn.fetch(table_stats_query)
            
            # M√©triques de verrouillage
            lock_stats_query = """
                SELECT 
                    mode,
                    count(*) as count
                FROM pg_locks 
                GROUP BY mode;
            """
            
            lock_stats = await conn.fetch(lock_stats_query)
            
            await conn.close()
            
            return {
                'connections': dict(connection_stats),
                'databases': [dict(row) for row in db_stats],
                'cache_hit_ratio': cache_hit_ratio,
                'top_tables': [dict(row) for row in table_stats],
                'locks': [dict(row) for row in lock_stats],
                'timestamp': datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Erreur collecte m√©triques PostgreSQL: {str(e)}")
            return None
    
    async def _collect_redis_metrics(self) -> Optional[Dict[str, Any]]:
        """Collecte les m√©triques Redis."""
        try:
            redis_url = self.config.tags.get('redis_url', 'redis://localhost:6379')
            redis = aioredis.from_url(redis_url)
            
            # Informations g√©n√©rales
            info = await redis.info()
            
            # M√©triques sp√©cifiques
            memory_info = await redis.info('memory')
            stats_info = await redis.info('stats')
            replication_info = await redis.info('replication')
            
            # M√©triques de performance
            slowlog = await redis.slowlog_get(10)
            
            # Utilisation des cl√©s par type
            key_types = {}
            for db_num in range(16):  # Redis a 16 bases par d√©faut
                try:
                    await redis.select(db_num)
                    keys = await redis.keys('*')
                    if keys:
                        for key in keys[:100]:  # Limite pour √©viter la surcharge
                            key_type = await redis.type(key)
                            key_types[key_type] = key_types.get(key_type, 0) + 1
                except:
                    continue
            
            await redis.close()
            
            return {
                'server_info': {
                    'version': info.get('redis_version'),
                    'uptime_in_seconds': info.get('uptime_in_seconds'),
                    'connected_clients': info.get('connected_clients'),
                    'blocked_clients': info.get('blocked_clients'),
                    'used_memory': memory_info.get('used_memory'),
                    'used_memory_human': memory_info.get('used_memory_human'),
                    'used_memory_rss': memory_info.get('used_memory_rss'),
                    'mem_fragmentation_ratio': memory_info.get('mem_fragmentation_ratio'),
                    'maxmemory': memory_info.get('maxmemory'),
                },
                'performance': {
                    'instantaneous_ops_per_sec': stats_info.get('instantaneous_ops_per_sec'),
                    'total_connections_received': stats_info.get('total_connections_received'),
                    'total_commands_processed': stats_info.get('total_commands_processed'),
                    'expired_keys': stats_info.get('expired_keys'),
                    'evicted_keys': stats_info.get('evicted_keys'),
                    'keyspace_hits': stats_info.get('keyspace_hits'),
                    'keyspace_misses': stats_info.get('keyspace_misses'),
                },
                'replication': replication_info,
                'slowlog': [
                    {
                        'id': entry[0],
                        'timestamp': entry[1],
                        'duration_microseconds': entry[2],
                        'command': ' '.join(str(arg, 'utf-8') if isinstance(arg, bytes) else str(arg) for arg in entry[3])
                    } for entry in slowlog
                ],
                'key_types_distribution': key_types,
                'timestamp': datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Erreur collecte m√©triques Redis: {str(e)}")
            return None
    
    async def _collect_mongo_metrics(self) -> Optional[Dict[str, Any]]:
        """Collecte les m√©triques MongoDB."""
        try:
            mongo_url = self.config.tags.get('mongo_url', 'mongodb://localhost:27017')
            client = pymongo.MongoClient(mongo_url)
            
            # Statistiques du serveur
            server_status = client.admin.command('serverStatus')
            
            # Statistiques des bases de donn√©es
            db_stats = {}
            for db_name in client.list_database_names():
                if db_name not in ['admin', 'local', 'config']:
                    db = client[db_name]
                    stats = db.command('dbStats')
                    db_stats[db_name] = {
                        'collections': stats.get('collections'),
                        'objects': stats.get('objects'),
                        'dataSize': stats.get('dataSize'),
                        'storageSize': stats.get('storageSize'),
                        'indexes': stats.get('indexes'),
                        'indexSize': stats.get('indexSize'),
                        'avgObjSize': stats.get('avgObjSize')
                    }
            
            # Profiling des requ√™tes lentes
            slow_queries = []
            try:
                for db_name in client.list_database_names():
                    if db_name not in ['admin', 'local', 'config']:
                        db = client[db_name]
                        profiler_data = db.system.profile.find().sort('ts', -1).limit(10)
                        for query in profiler_data:
                            slow_queries.append({
                                'database': db_name,
                                'timestamp': query.get('ts'),
                                'duration_ms': query.get('millis'),
                                'operation': query.get('op'),
                                'namespace': query.get('ns'),
                                'command': str(query.get('command', {}))[:200]  # Limit√© pour √©viter trop de donn√©es
                            })
            except:
                pass  # Le profiling peut ne pas √™tre activ√©
            
            client.close()
            
            return {
                'server_info': {
                    'version': server_status.get('version'),
                    'uptime': server_status.get('uptime'),
                    'connections': server_status.get('connections', {}),
                    'network': server_status.get('network', {}),
                    'opcounters': server_status.get('opcounters', {}),
                    'memory': server_status.get('mem', {}),
                },
                'databases': db_stats,
                'slow_queries': slow_queries,
                'wired_tiger': server_status.get('wiredTiger', {}),
                'timestamp': datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Erreur collecte m√©triques MongoDB: {str(e)}")
            return None
    
    async def validate_data(self, data: Dict[str, Any]) -> bool:
        """Valide les donn√©es de performance des bases de donn√©es."""
        try:
            db_perf = data.get('database_performance', {})
            
            # Validation PostgreSQL
            if 'postgresql' in db_perf:
                pg_data = db_perf['postgresql']
                connections = pg_data.get('connections', {})
                if 'total_connections' not in connections:
                    return False
            
            # Validation Redis
            if 'redis' in db_perf:
                redis_data = db_perf['redis']
                if 'server_info' not in redis_data:
                    return False
            
            # Validation MongoDB
            if 'mongodb' in db_perf:
                mongo_data = db_perf['mongodb']
                if 'server_info' not in mongo_data:
                    return False
            
            return True
            
        except Exception as e:
            logger.error(f"Erreur validation donn√©es DB: {str(e)}")
            return False


class APIPerformanceCollector(BaseCollector):
    """Collecteur de performances des APIs."""
    
    def __init__(self, config: CollectorConfig):
        super().__init__(config)
        self.request_history = []
        self.endpoint_stats = {}
    
    async def collect(self) -> Dict[str, Any]:
        """Collecte les m√©triques de performance des APIs."""
        # Cette m√©thode serait int√©gr√©e avec le middleware FastAPI
        # pour collecter les m√©triques de requ√™tes en temps r√©el
        
        return {
            'api_performance': {
                'total_requests': len(self.request_history),
                'endpoints_stats': self.endpoint_stats,
                'average_response_time': self._calculate_avg_response_time(),
                'error_rate': self._calculate_error_rate(),
                'top_slow_endpoints': self._get_slow_endpoints(),
                'timestamp': datetime.utcnow().isoformat()
            }
        }
    
    def _calculate_avg_response_time(self) -> float:
        """Calcule le temps de r√©ponse moyen."""
        if not self.request_history:
            return 0.0
        
        recent_requests = [
            req for req in self.request_history 
            if datetime.utcnow() - req['timestamp'] < timedelta(minutes=5)
        ]
        
        if not recent_requests:
            return 0.0
        
        return statistics.mean([req['response_time'] for req in recent_requests])
    
    def _calculate_error_rate(self) -> float:
        """Calcule le taux d'erreur."""
        if not self.request_history:
            return 0.0
        
        recent_requests = [
            req for req in self.request_history 
            if datetime.utcnow() - req['timestamp'] < timedelta(minutes=5)
        ]
        
        if not recent_requests:
            return 0.0
        
        error_count = sum(1 for req in recent_requests if req['status_code'] >= 400)
        return error_count / len(recent_requests)
    
    def _get_slow_endpoints(self) -> List[Dict[str, Any]]:
        """Retourne les endpoints les plus lents."""
        endpoint_times = {}
        
        for req in self.request_history:
            endpoint = req['endpoint']
            if endpoint not in endpoint_times:
                endpoint_times[endpoint] = []
            endpoint_times[endpoint].append(req['response_time'])
        
        slow_endpoints = []
        for endpoint, times in endpoint_times.items():
            avg_time = statistics.mean(times)
            slow_endpoints.append({
                'endpoint': endpoint,
                'average_time': avg_time,
                'request_count': len(times)
            })
        
        return sorted(slow_endpoints, key=lambda x: x['average_time'], reverse=True)[:10]
    
    async def validate_data(self, data: Dict[str, Any]) -> bool:
        """Valide les donn√©es de performance API."""
        try:
            api_perf = data.get('api_performance', {})
            required_fields = ['total_requests', 'average_response_time', 'error_rate']
            
            for field in required_fields:
                if field not in api_perf:
                    return False
            
            # Validation des valeurs
            if api_perf['error_rate'] < 0 or api_perf['error_rate'] > 1:
                return False
            
            if api_perf['average_response_time'] < 0:
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"Erreur validation donn√©es API: {str(e)}")
            return False


class PerformanceAnomalyDetector:
    """D√©tecteur d'anomalies pour les m√©triques de performance."""
    
    def __init__(self):
        self.baseline_metrics = {}
        self.anomaly_threshold = 2.0  # √âcart-type
    
    async def detect_anomalies(self, metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
        """D√©tecte les anomalies dans les m√©triques."""
        anomalies = []
        
        # Extraction des m√©triques cl√©s
        system_perf = metrics.get('system_performance', {})
        
        # V√©rification CPU
        cpu_percent = system_perf.get('cpu', {}).get('percent_total')
        if cpu_percent and cpu_percent > 90:
            anomalies.append({
                'type': 'cpu_high',
                'value': cpu_percent,
                'threshold': 90,
                'severity': 'critical',
                'message': f'Utilisation CPU critique: {cpu_percent}%'
            })
        
        # V√©rification m√©moire
        memory_percent = system_perf.get('memory', {}).get('percent')
        if memory_percent and memory_percent > 85:
            anomalies.append({
                'type': 'memory_high',
                'value': memory_percent,
                'threshold': 85,
                'severity': 'warning' if memory_percent < 95 else 'critical',
                'message': f'Utilisation m√©moire √©lev√©e: {memory_percent}%'
            })
        
        # V√©rification disque
        disk_usage = system_perf.get('disk', {}).get('usage_by_partition', {})
        for partition, usage in disk_usage.items():
            if usage.get('percent', 0) > 90:
                anomalies.append({
                    'type': 'disk_space_high',
                    'value': usage['percent'],
                    'threshold': 90,
                    'severity': 'critical',
                    'message': f'Espace disque critique sur {partition}: {usage["percent"]}%'
                })
        
        return anomalies


__all__ = [
    'SystemPerformanceCollector',
    'DatabasePerformanceCollector', 
    'APIPerformanceCollector',
    'PerformanceAnomalyDetector',
    'PerformanceMetrics'
]
