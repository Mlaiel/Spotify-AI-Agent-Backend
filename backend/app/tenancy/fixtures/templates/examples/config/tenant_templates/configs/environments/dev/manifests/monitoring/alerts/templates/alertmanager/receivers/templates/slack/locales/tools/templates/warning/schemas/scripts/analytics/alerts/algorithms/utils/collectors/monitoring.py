"""
Spotify AI Agent - Advanced Monitoring Module
============================================

Syst√®me de monitoring ultra-avanc√© pour les collecteurs de donn√©es
avec observabilit√© compl√®te, alerting intelligent, et analytics en temps r√©el.

Fonctionnalit√©s de monitoring:
- M√©triques Prometheus avec labels dynamiques
- Alerting bas√© sur des seuils adaptatifs
- Dashboards Grafana automatis√©s
- Tracing distribu√© avec OpenTelemetry
- Health checks intelligents
- Analytics de performance en temps r√©el
- D√©tection d'anomalies avec ML
- Corr√©lation d'√©v√©nements
- Monitoring business et technique

D√©velopp√© par l'√©quipe Spotify AI Agent
Lead Developer: Fahed Mlaiel
Architecture: Enterprise-grade multi-tenant monitoring system
"""

import asyncio
import time
import threading
import weakref
from collections import defaultdict, deque
from contextlib import asynccontextmanager
from dataclasses import dataclass, field
from datetime import datetime, timedelta, timezone
from enum import Enum
from functools import wraps
from pathlib import Path
from typing import (
    Any, Dict, List, Optional, Union, Callable, Tuple, 
    Set, Awaitable, Type, Protocol, NamedTuple
)
import json
import logging
import structlog
import psutil
import socket
import threading
from concurrent.futures import ThreadPoolExecutor
import aiohttp
import aiofiles
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import prometheus_client
from prometheus_client import (
    Counter, Histogram, Gauge, Summary, Info, Enum as PrometheusEnum,
    CollectorRegistry, generate_latest, CONTENT_TYPE_LATEST
)
from opentelemetry import trace, metrics
from opentelemetry.exporter.prometheus import PrometheusMetricReader
from opentelemetry.sdk.metrics import MeterProvider
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
import redis.asyncio as aioredis
from pydantic import BaseModel, validator
import asyncpg


logger = structlog.get_logger(__name__)


class MetricType(Enum):
    """Types de m√©triques support√©es."""
    COUNTER = "counter"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"
    SUMMARY = "summary"
    INFO = "info"
    ENUM = "enum"


class AlertSeverity(Enum):
    """Niveaux de s√©v√©rit√© des alertes."""
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"
    FATAL = "fatal"


class HealthStatus(Enum):
    """√âtats de sant√© des composants."""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    UNKNOWN = "unknown"


@dataclass
class MetricDefinition:
    """D√©finition d'une m√©trique."""
    
    name: str
    metric_type: MetricType
    description: str
    labels: List[str] = field(default_factory=list)
    buckets: Optional[List[float]] = None  # Pour histogrammes
    quantiles: Optional[List[float]] = None  # Pour summaries
    unit: Optional[str] = None
    namespace: str = "spotify_ai_agent"
    subsystem: str = "collectors"


@dataclass
class AlertRule:
    """R√®gle d'alerte."""
    
    name: str
    metric_name: str
    condition: str  # ex: ">" , "<", "==", "!=", ">=", "<="
    threshold: float
    duration: int  # Dur√©e en secondes
    severity: AlertSeverity
    description: str
    labels: Dict[str, str] = field(default_factory=dict)
    annotations: Dict[str, str] = field(default_factory=dict)
    enabled: bool = True
    cooldown: int = 300  # P√©riode de cooldown en secondes


@dataclass
class HealthCheck:
    """V√©rification de sant√© d'un composant."""
    
    name: str
    check_function: Callable[[], Awaitable[Tuple[HealthStatus, str]]]
    interval: int = 30  # Intervalle en secondes
    timeout: int = 10  # Timeout en secondes
    retries: int = 3
    enabled: bool = True
    critical: bool = False  # Si True, l'√©chec affecte la sant√© globale


class MetricsCollector:
    """
    Collecteur de m√©triques avanc√© avec support Prometheus et OpenTelemetry.
    
    Fonctionnalit√©s:
    - M√©triques personnalis√©es avec labels dynamiques
    - Export Prometheus automatique
    - Int√©gration OpenTelemetry
    - Agr√©gation en temps r√©el
    - Persistence des m√©triques
    """
    
    def __init__(
        self,
        registry: Optional[CollectorRegistry] = None,
        enable_opentelemetry: bool = True,
        export_port: int = 9090,
        namespace: str = "spotify_ai_agent"
    ):
        self.registry = registry or CollectorRegistry()
        self.enable_opentelemetry = enable_opentelemetry
        self.export_port = export_port
        self.namespace = namespace
        
        # Stockage des m√©triques
        self._metrics: Dict[str, Any] = {}
        self._metric_definitions: Dict[str, MetricDefinition] = {}
        
        # OpenTelemetry setup
        if enable_opentelemetry:
            self._setup_opentelemetry()
        
        # Cache pour l'agr√©gation
        self._aggregation_cache: Dict[str, deque] = defaultdict(lambda: deque(maxlen=1000))
        self._last_aggregation = time.time()
        
        # M√©triques syst√®me automatiques
        self._system_metrics_enabled = True
        self._system_collection_task = None
        
        # D√©marrage des t√¢ches de collecte
        asyncio.create_task(self._start_background_tasks())
    
    def _setup_opentelemetry(self) -> None:
        """Configure OpenTelemetry pour les m√©triques et traces."""
        
        # Configuration du provider de m√©triques
        metric_reader = PrometheusMetricReader()
        meter_provider = MeterProvider(metric_readers=[metric_reader])
        metrics.set_meter_provider(meter_provider)
        self.meter = metrics.get_meter(__name__)
        
        # Configuration du tracing
        trace.set_tracer_provider(TracerProvider())
        
        # Export vers Jaeger (si configur√©)
        jaeger_exporter = JaegerExporter(
            agent_host_name="localhost",
            agent_port=14268,
        )
        
        span_processor = BatchSpanProcessor(jaeger_exporter)
        trace.get_tracer_provider().add_span_processor(span_processor)
        
        self.tracer = trace.get_tracer(__name__)
    
    async def _start_background_tasks(self) -> None:
        """D√©marre les t√¢ches de collecte en arri√®re-plan."""
        if self._system_metrics_enabled:
            self._system_collection_task = asyncio.create_task(self._collect_system_metrics())
    
    def register_metric(self, definition: MetricDefinition) -> None:
        """Enregistre une nouvelle m√©trique."""
        
        full_name = f"{definition.namespace}_{definition.subsystem}_{definition.name}"
        
        if definition.metric_type == MetricType.COUNTER:
            metric = Counter(
                full_name,
                definition.description,
                definition.labels,
                registry=self.registry
            )
        elif definition.metric_type == MetricType.GAUGE:
            metric = Gauge(
                full_name,
                definition.description,
                definition.labels,
                registry=self.registry
            )
        elif definition.metric_type == MetricType.HISTOGRAM:
            metric = Histogram(
                full_name,
                definition.description,
                definition.labels,
                buckets=definition.buckets,
                registry=self.registry
            )
        elif definition.metric_type == MetricType.SUMMARY:
            metric = Summary(
                full_name,
                definition.description,
                definition.labels,
                registry=self.registry
            )
        elif definition.metric_type == MetricType.INFO:
            metric = Info(
                full_name,
                definition.description,
                registry=self.registry
            )
        elif definition.metric_type == MetricType.ENUM:
            # Enum n√©cessite des √©tats pr√©d√©finis
            metric = PrometheusEnum(
                full_name,
                definition.description,
                definition.labels,
                states=['unknown'],  # √âtat par d√©faut
                registry=self.registry
            )
        else:
            raise ValueError(f"Type de m√©trique non support√©: {definition.metric_type}")
        
        self._metrics[definition.name] = metric
        self._metric_definitions[definition.name] = definition
        
        logger.info(
            "M√©trique enregistr√©e",
            name=definition.name,
            type=definition.metric_type.value,
            labels=definition.labels
        )
    
    def increment_counter(self, name: str, value: float = 1.0, labels: Optional[Dict[str, str]] = None) -> None:
        """Incr√©mente un counter."""
        if name not in self._metrics:
            logger.warning("M√©trique non trouv√©e", name=name)
            return
        
        metric = self._metrics[name]
        if not isinstance(metric, Counter):
            logger.error("Type de m√©trique incorrect", name=name, expected="Counter")
            return
        
        if labels:
            metric.labels(**labels).inc(value)
        else:
            metric.inc(value)
    
    def set_gauge(self, name: str, value: float, labels: Optional[Dict[str, str]] = None) -> None:
        """D√©finit la valeur d'une gauge."""
        if name not in self._metrics:
            logger.warning("M√©trique non trouv√©e", name=name)
            return
        
        metric = self._metrics[name]
        if not isinstance(metric, Gauge):
            logger.error("Type de m√©trique incorrect", name=name, expected="Gauge")
            return
        
        if labels:
            metric.labels(**labels).set(value)
        else:
            metric.set(value)
    
    def observe_histogram(self, name: str, value: float, labels: Optional[Dict[str, str]] = None) -> None:
        """Ajoute une observation √† un histogramme."""
        if name not in self._metrics:
            logger.warning("M√©trique non trouv√©e", name=name)
            return
        
        metric = self._metrics[name]
        if not isinstance(metric, Histogram):
            logger.error("Type de m√©trique incorrect", name=name, expected="Histogram")
            return
        
        if labels:
            metric.labels(**labels).observe(value)
        else:
            metric.observe(value)
    
    def observe_summary(self, name: str, value: float, labels: Optional[Dict[str, str]] = None) -> None:
        """Ajoute une observation √† un summary."""
        if name not in self._metrics:
            logger.warning("M√©trique non trouv√©e", name=name)
            return
        
        metric = self._metrics[name]
        if not isinstance(metric, Summary):
            logger.error("Type de m√©trique incorrect", name=name, expected="Summary")
            return
        
        if labels:
            metric.labels(**labels).observe(value)
        else:
            metric.observe(value)
    
    async def _collect_system_metrics(self) -> None:
        """Collecte automatique des m√©triques syst√®me."""
        
        # Enregistrement des m√©triques syst√®me si pas d√©j√† fait
        system_metrics = [
            MetricDefinition("cpu_usage_percent", MetricType.GAUGE, "Utilisation CPU en pourcentage"),
            MetricDefinition("memory_usage_bytes", MetricType.GAUGE, "Utilisation m√©moire en bytes"),
            MetricDefinition("memory_usage_percent", MetricType.GAUGE, "Utilisation m√©moire en pourcentage"),
            MetricDefinition("disk_usage_bytes", MetricType.GAUGE, "Utilisation disque en bytes", ["path"]),
            MetricDefinition("disk_usage_percent", MetricType.GAUGE, "Utilisation disque en pourcentage", ["path"]),
            MetricDefinition("network_bytes_sent", MetricType.COUNTER, "Bytes r√©seau envoy√©s", ["interface"]),
            MetricDefinition("network_bytes_recv", MetricType.COUNTER, "Bytes r√©seau re√ßus", ["interface"]),
            MetricDefinition("process_count", MetricType.GAUGE, "Nombre de processus"),
            MetricDefinition("load_average", MetricType.GAUGE, "Charge moyenne du syst√®me", ["period"]),
        ]
        
        for metric_def in system_metrics:
            if metric_def.name not in self._metrics:
                self.register_metric(metric_def)
        
        while True:
            try:
                # CPU
                cpu_percent = psutil.cpu_percent(interval=1)
                self.set_gauge("cpu_usage_percent", cpu_percent)
                
                # M√©moire
                memory = psutil.virtual_memory()
                self.set_gauge("memory_usage_bytes", memory.used)
                self.set_gauge("memory_usage_percent", memory.percent)
                
                # Disque
                for partition in psutil.disk_partitions():
                    try:
                        disk_usage = psutil.disk_usage(partition.mountpoint)
                        self.set_gauge("disk_usage_bytes", disk_usage.used, {"path": partition.mountpoint})
                        self.set_gauge("disk_usage_percent", 
                                     (disk_usage.used / disk_usage.total) * 100,
                                     {"path": partition.mountpoint})
                    except PermissionError:
                        continue
                
                # R√©seau
                network_io = psutil.net_io_counters(pernic=True)
                for interface, stats in network_io.items():
                    self.set_gauge("network_bytes_sent", stats.bytes_sent, {"interface": interface})
                    self.set_gauge("network_bytes_recv", stats.bytes_recv, {"interface": interface})
                
                # Processus
                self.set_gauge("process_count", len(psutil.pids()))
                
                # Charge syst√®me (Linux uniquement)
                try:
                    load_avg = psutil.getloadavg()
                    self.set_gauge("load_average", load_avg[0], {"period": "1min"})
                    self.set_gauge("load_average", load_avg[1], {"period": "5min"})
                    self.set_gauge("load_average", load_avg[2], {"period": "15min"})
                except AttributeError:
                    pass  # getloadavg n'est pas disponible sur tous les OS
                
                await asyncio.sleep(30)  # Collecte toutes les 30 secondes
                
            except Exception as e:
                logger.error("Erreur lors de la collecte des m√©triques syst√®me", error=str(e))
                await asyncio.sleep(60)
    
    def get_prometheus_metrics(self) -> str:
        """Retourne les m√©triques au format Prometheus."""
        return generate_latest(self.registry).decode('utf-8')
    
    def get_metric_families(self) -> List[Any]:
        """Retourne les familles de m√©triques."""
        return list(self.registry.collect())


class AlertManager:
    """
    Gestionnaire d'alertes avanc√© avec seuils adaptatifs et ML.
    
    Fonctionnalit√©s:
    - R√®gles d'alertes dynamiques
    - Seuils adaptatifs bas√©s sur l'historique
    - D√©tection d'anomalies avec Machine Learning
    - Corr√©lation d'√©v√©nements
    - Escalation automatique
    - Int√©gration Slack/Email/PagerDuty
    """
    
    def __init__(
        self,
        metrics_collector: MetricsCollector,
        enable_ml_detection: bool = True,
        webhook_urls: Optional[Dict[str, str]] = None
    ):
        self.metrics_collector = metrics_collector
        self.enable_ml_detection = enable_ml_detection
        self.webhook_urls = webhook_urls or {}
        
        # Stockage des r√®gles et √©tats
        self._alert_rules: Dict[str, AlertRule] = {}
        self._active_alerts: Dict[str, Dict[str, Any]] = {}
        self._alert_history: deque = deque(maxlen=10000)
        
        # D√©tection d'anomalies ML
        if enable_ml_detection:
            self._setup_ml_detection()
        
        # Cache pour les donn√©es historiques
        self._historical_data: Dict[str, deque] = defaultdict(lambda: deque(maxlen=10000))
        
        # T√¢che de v√©rification des alertes
        self._alert_check_task = None
        
        # D√©marrage du monitoring
        asyncio.create_task(self._start_alert_monitoring())
    
    def _setup_ml_detection(self) -> None:
        """Configure la d√©tection d'anomalies par Machine Learning."""
        self.anomaly_detector = IsolationForest(
            contamination=0.1,  # 10% d'anomalies attendues
            random_state=42
        )
        self.scaler = StandardScaler()
        self._ml_training_data: Dict[str, List[float]] = defaultdict(list)
        self._ml_models_trained = False
    
    async def _start_alert_monitoring(self) -> None:
        """D√©marre le monitoring des alertes."""
        self._alert_check_task = asyncio.create_task(self._alert_monitoring_loop())
    
    def register_alert_rule(self, rule: AlertRule) -> None:
        """Enregistre une nouvelle r√®gle d'alerte."""
        self._alert_rules[rule.name] = rule
        
        logger.info(
            "R√®gle d'alerte enregistr√©e",
            name=rule.name,
            metric=rule.metric_name,
            condition=rule.condition,
            threshold=rule.threshold,
            severity=rule.severity.value
        )
    
    async def _alert_monitoring_loop(self) -> None:
        """Boucle principale de monitoring des alertes."""
        while True:
            try:
                await self._check_all_alerts()
                await self._update_ml_models()
                await asyncio.sleep(10)  # V√©rification toutes les 10 secondes
            except Exception as e:
                logger.error("Erreur dans la boucle de monitoring", error=str(e))
                await asyncio.sleep(30)
    
    async def _check_all_alerts(self) -> None:
        """V√©rifie toutes les r√®gles d'alertes."""
        
        # R√©cup√©ration des m√©triques actuelles
        current_metrics = await self._get_current_metrics()
        
        for rule_name, rule in self._alert_rules.items():
            if not rule.enabled:
                continue
            
            try:
                await self._check_alert_rule(rule, current_metrics)
            except Exception as e:
                logger.error(
                    "Erreur lors de la v√©rification d'une r√®gle",
                    rule_name=rule_name,
                    error=str(e)
                )
    
    async def _get_current_metrics(self) -> Dict[str, float]:
        """R√©cup√®re les valeurs actuelles des m√©triques."""
        
        current_metrics = {}
        
        # Extraction des valeurs depuis le registry Prometheus
        for family in self.metrics_collector.get_metric_families():
            for sample in family.samples:
                metric_name = sample.name
                value = sample.value
                
                # Stockage de la valeur (on prend la derni√®re pour les m√©triques avec labels)
                current_metrics[metric_name] = value
                
                # Ajout √† l'historique pour ML
                if self.enable_ml_detection:
                    self._ml_training_data[metric_name].append(value)
                    if len(self._ml_training_data[metric_name]) > 1000:
                        self._ml_training_data[metric_name].pop(0)
        
        return current_metrics
    
    async def _check_alert_rule(self, rule: AlertRule, current_metrics: Dict[str, float]) -> None:
        """V√©rifie une r√®gle d'alerte sp√©cifique."""
        
        if rule.metric_name not in current_metrics:
            return
        
        current_value = current_metrics[rule.metric_name]
        threshold = rule.threshold
        
        # Adaptation du seuil si demand√©
        if rule.metric_name in self._historical_data:
            threshold = await self._calculate_adaptive_threshold(rule)
        
        # V√©rification de la condition
        alert_triggered = self._evaluate_condition(current_value, rule.condition, threshold)
        
        alert_key = f"{rule.name}_{rule.metric_name}"
        
        if alert_triggered:
            if alert_key not in self._active_alerts:
                # Nouvelle alerte
                alert_data = {
                    "rule": rule,
                    "triggered_at": time.time(),
                    "current_value": current_value,
                    "threshold": threshold,
                    "count": 1
                }
                self._active_alerts[alert_key] = alert_data
                
                # V√©rification de la dur√©e avant d√©clenchement
                if rule.duration == 0:
                    await self._fire_alert(alert_data)
            else:
                # Alerte existante - mise √† jour
                alert_data = self._active_alerts[alert_key]
                alert_data["current_value"] = current_value
                alert_data["count"] += 1
                
                # V√©rification si la dur√©e est atteinte
                duration_passed = time.time() - alert_data["triggered_at"]
                if duration_passed >= rule.duration:
                    await self._fire_alert(alert_data)
        else:
            # Condition non remplie - r√©solution de l'alerte si active
            if alert_key in self._active_alerts:
                await self._resolve_alert(alert_key)
    
    def _evaluate_condition(self, current_value: float, condition: str, threshold: float) -> bool:
        """√âvalue une condition d'alerte."""
        
        if condition == ">":
            return current_value > threshold
        elif condition == "<":
            return current_value < threshold
        elif condition == ">=":
            return current_value >= threshold
        elif condition == "<=":
            return current_value <= threshold
        elif condition == "==":
            return abs(current_value - threshold) < 0.001  # Tol√©rance pour float
        elif condition == "!=":
            return abs(current_value - threshold) >= 0.001
        else:
            logger.error("Condition d'alerte non support√©e", condition=condition)
            return False
    
    async def _calculate_adaptive_threshold(self, rule: AlertRule) -> float:
        """Calcule un seuil adaptatif bas√© sur l'historique."""
        
        if rule.metric_name not in self._historical_data:
            return rule.threshold
        
        historical_values = list(self._historical_data[rule.metric_name])
        
        if len(historical_values) < 10:
            return rule.threshold
        
        # Statistiques de base
        mean_value = np.mean(historical_values)
        std_value = np.std(historical_values)
        
        # Ajustement du seuil bas√© sur l'√©cart type
        if rule.condition in [">", ">="]:
            # Pour les alertes de d√©passement, seuil = moyenne + N * √©cart-type
            adaptive_threshold = mean_value + (2 * std_value)
        else:
            # Pour les alertes de sous-performance, seuil = moyenne - N * √©cart-type
            adaptive_threshold = mean_value - (2 * std_value)
        
        # Hybridation avec le seuil fixe (70% adaptatif, 30% fixe)
        final_threshold = (adaptive_threshold * 0.7) + (rule.threshold * 0.3)
        
        return final_threshold
    
    async def _fire_alert(self, alert_data: Dict[str, Any]) -> None:
        """D√©clenche une alerte."""
        
        rule = alert_data["rule"]
        
        # V√©rification du cooldown
        if await self._is_in_cooldown(rule.name):
            return
        
        # Cr√©ation du message d'alerte
        alert_message = {
            "alert_name": rule.name,
            "metric_name": rule.metric_name,
            "severity": rule.severity.value,
            "description": rule.description,
            "current_value": alert_data["current_value"],
            "threshold": alert_data["threshold"],
            "condition": rule.condition,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "labels": rule.labels,
            "annotations": rule.annotations
        }
        
        # Ajout √† l'historique
        self._alert_history.append(alert_message)
        
        # Envoi des notifications
        await self._send_alert_notifications(alert_message)
        
        # Mise √† jour du cooldown
        self._active_alerts[f"{rule.name}_{rule.metric_name}"]["last_fired"] = time.time()
        
        logger.error(
            "Alerte d√©clench√©e",
            **{k: v for k, v in alert_message.items() if k not in ['labels', 'annotations']}
        )
    
    async def _resolve_alert(self, alert_key: str) -> None:
        """R√©sout une alerte active."""
        
        if alert_key in self._active_alerts:
            alert_data = self._active_alerts[alert_key]
            rule = alert_data["rule"]
            
            resolution_message = {
                "alert_name": rule.name,
                "metric_name": rule.metric_name,
                "severity": "resolved",
                "description": f"Alerte r√©solue: {rule.description}",
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "duration": time.time() - alert_data["triggered_at"]
            }
            
            # Envoi de la notification de r√©solution
            await self._send_resolution_notifications(resolution_message)
            
            # Suppression de l'alerte active
            del self._active_alerts[alert_key]
            
            logger.info(
                "Alerte r√©solue",
                alert_name=rule.name,
                metric_name=rule.metric_name,
                duration=resolution_message["duration"]
            )
    
    async def _is_in_cooldown(self, rule_name: str) -> bool:
        """V√©rifie si une r√®gle est en p√©riode de cooldown."""
        
        for alert_key, alert_data in self._active_alerts.items():
            if alert_data["rule"].name == rule_name:
                last_fired = alert_data.get("last_fired", 0)
                cooldown_period = alert_data["rule"].cooldown
                
                if time.time() - last_fired < cooldown_period:
                    return True
        
        return False
    
    async def _send_alert_notifications(self, alert_message: Dict[str, Any]) -> None:
        """Envoie les notifications d'alerte."""
        
        # Slack
        if "slack" in self.webhook_urls:
            await self._send_slack_notification(alert_message)
        
        # Email (√† impl√©menter)
        # if "email" in self.webhook_urls:
        #     await self._send_email_notification(alert_message)
        
        # PagerDuty (√† impl√©menter)
        # if "pagerduty" in self.webhook_urls:
        #     await self._send_pagerduty_notification(alert_message)
    
    async def _send_resolution_notifications(self, resolution_message: Dict[str, Any]) -> None:
        """Envoie les notifications de r√©solution."""
        
        if "slack" in self.webhook_urls:
            await self._send_slack_resolution(resolution_message)
    
    async def _send_slack_notification(self, alert_message: Dict[str, Any]) -> None:
        """Envoie une notification Slack."""
        
        try:
            webhook_url = self.webhook_urls["slack"]
            
            # Couleur selon la s√©v√©rit√©
            color_map = {
                "info": "#36a64f",
                "warning": "#ff9900", 
                "critical": "#ff0000",
                "fatal": "#800000"
            }
            
            color = color_map.get(alert_message["severity"], "#ff0000")
            
            slack_payload = {
                "attachments": [
                    {
                        "color": color,
                        "title": f"üö® Alerte: {alert_message['alert_name']}",
                        "text": alert_message["description"],
                        "fields": [
                            {
                                "title": "M√©trique",
                                "value": alert_message["metric_name"],
                                "short": True
                            },
                            {
                                "title": "Valeur actuelle",
                                "value": f"{alert_message['current_value']:.2f}",
                                "short": True
                            },
                            {
                                "title": "Seuil",
                                "value": f"{alert_message['condition']} {alert_message['threshold']:.2f}",
                                "short": True
                            },
                            {
                                "title": "S√©v√©rit√©",
                                "value": alert_message["severity"].upper(),
                                "short": True
                            }
                        ],
                        "timestamp": int(time.time())
                    }
                ]
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(webhook_url, json=slack_payload) as response:
                    if response.status != 200:
                        logger.error(
                            "Erreur lors de l'envoi Slack",
                            status=response.status,
                            response=await response.text()
                        )
        
        except Exception as e:
            logger.error("Erreur lors de l'envoi de notification Slack", error=str(e))
    
    async def _send_slack_resolution(self, resolution_message: Dict[str, Any]) -> None:
        """Envoie une notification de r√©solution Slack."""
        
        try:
            webhook_url = self.webhook_urls["slack"]
            
            slack_payload = {
                "attachments": [
                    {
                        "color": "#36a64f",
                        "title": f"‚úÖ Alerte r√©solue: {resolution_message['alert_name']}",
                        "text": resolution_message["description"],
                        "fields": [
                            {
                                "title": "Dur√©e",
                                "value": f"{resolution_message['duration']:.0f} secondes",
                                "short": True
                            }
                        ],
                        "timestamp": int(time.time())
                    }
                ]
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(webhook_url, json=slack_payload) as response:
                    if response.status != 200:
                        logger.error(
                            "Erreur lors de l'envoi Slack r√©solution",
                            status=response.status
                        )
        
        except Exception as e:
            logger.error("Erreur lors de l'envoi de r√©solution Slack", error=str(e))
    
    async def _update_ml_models(self) -> None:
        """Met √† jour les mod√®les de d√©tection d'anomalies."""
        
        if not self.enable_ml_detection:
            return
        
        # Mise √† jour p√©riodique (toutes les heures)
        current_time = time.time()
        if not hasattr(self, '_last_ml_update'):
            self._last_ml_update = current_time
        
        if current_time - self._last_ml_update < 3600:  # 1 heure
            return
        
        # Entra√Ænement des mod√®les avec les nouvelles donn√©es
        for metric_name, data in self._ml_training_data.items():
            if len(data) >= 100:  # Minimum de donn√©es pour l'entra√Ænement
                try:
                    # Pr√©paration des donn√©es
                    X = np.array(data).reshape(-1, 1)
                    X_scaled = self.scaler.fit_transform(X)
                    
                    # Entra√Ænement du mod√®le
                    self.anomaly_detector.fit(X_scaled)
                    
                    # D√©tection d'anomalies sur les derni√®res valeurs
                    recent_data = X_scaled[-10:]  # 10 derni√®res valeurs
                    anomalies = self.anomaly_detector.predict(recent_data)
                    
                    # G√©n√©ration d'alertes pour les anomalies d√©tect√©es
                    for i, is_anomaly in enumerate(anomalies):
                        if is_anomaly == -1:  # Anomalie d√©tect√©e
                            await self._generate_ml_alert(metric_name, data[-(10-i)])
                
                except Exception as e:
                    logger.error(
                        "Erreur lors de l'entra√Ænement ML",
                        metric_name=metric_name,
                        error=str(e)
                    )
        
        self._last_ml_update = current_time
        self._ml_models_trained = True
    
    async def _generate_ml_alert(self, metric_name: str, anomalous_value: float) -> None:
        """G√©n√®re une alerte bas√©e sur la d√©tection ML d'anomalie."""
        
        alert_message = {
            "alert_name": f"ml_anomaly_{metric_name}",
            "metric_name": metric_name,
            "severity": "warning",
            "description": f"Anomalie d√©tect√©e par ML sur la m√©trique {metric_name}",
            "current_value": anomalous_value,
            "threshold": "ML_DETECTED",
            "condition": "anomaly",
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "labels": {"type": "ml_anomaly"},
            "annotations": {"algorithm": "isolation_forest"}
        }
        
        # Ajout √† l'historique
        self._alert_history.append(alert_message)
        
        # Envoi des notifications si configur√©es
        await self._send_alert_notifications(alert_message)
        
        logger.warning(
            "Anomalie ML d√©tect√©e",
            metric_name=metric_name,
            value=anomalous_value
        )
    
    def get_active_alerts(self) -> List[Dict[str, Any]]:
        """Retourne la liste des alertes actives."""
        
        active_alerts = []
        for alert_key, alert_data in self._active_alerts.items():
            rule = alert_data["rule"]
            active_alerts.append({
                "name": rule.name,
                "metric_name": rule.metric_name,
                "severity": rule.severity.value,
                "triggered_at": alert_data["triggered_at"],
                "current_value": alert_data["current_value"],
                "threshold": alert_data.get("threshold", rule.threshold),
                "count": alert_data["count"]
            })
        
        return active_alerts
    
    def get_alert_history(self, limit: int = 100) -> List[Dict[str, Any]]:
        """Retourne l'historique des alertes."""
        return list(self._alert_history)[-limit:]
    
    def get_alert_statistics(self) -> Dict[str, Any]:
        """Retourne les statistiques des alertes."""
        
        total_alerts = len(self._alert_history)
        active_count = len(self._active_alerts)
        
        # Comptage par s√©v√©rit√©
        severity_counts = defaultdict(int)
        for alert in self._alert_history:
            severity_counts[alert["severity"]] += 1
        
        # M√©triques les plus probl√©matiques
        metric_counts = defaultdict(int)
        for alert in self._alert_history:
            metric_counts[alert["metric_name"]] += 1
        
        top_metrics = sorted(metric_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        
        return {
            "total_alerts": total_alerts,
            "active_alerts": active_count,
            "severity_breakdown": dict(severity_counts),
            "top_problematic_metrics": top_metrics,
            "ml_models_trained": getattr(self, '_ml_models_trained', False)
        }


class HealthMonitor:
    """
    Moniteur de sant√© des composants avec checks intelligents.
    
    Fonctionnalit√©s:
    - Health checks p√©riodiques
    - D√©tection de d√©gradation progressive
    - Corr√©lation de sant√© entre composants
    - Auto-healing basique
    - Rapports de sant√© d√©taill√©s
    """
    
    def __init__(self, metrics_collector: MetricsCollector):
        self.metrics_collector = metrics_collector
        
        # Stockage des checks et r√©sultats
        self._health_checks: Dict[str, HealthCheck] = {}
        self._health_status: Dict[str, HealthStatus] = {}
        self._health_history: Dict[str, deque] = defaultdict(lambda: deque(maxlen=1000))
        
        # √âtat global
        self._global_health = HealthStatus.UNKNOWN
        
        # T√¢che de monitoring
        self._health_monitoring_task = None
        
        # M√©triques de sant√©
        self._register_health_metrics()
        
        # D√©marrage du monitoring
        asyncio.create_task(self._start_health_monitoring())
    
    def _register_health_metrics(self) -> None:
        """Enregistre les m√©triques de sant√©."""
        
        health_metrics = [
            MetricDefinition(
                "component_health_status",
                MetricType.GAUGE,
                "Statut de sant√© des composants (0=unhealthy, 1=degraded, 2=healthy)",
                ["component"]
            ),
            MetricDefinition(
                "health_check_duration_seconds",
                MetricType.HISTOGRAM,
                "Dur√©e des health checks",
                ["component"],
                buckets=[0.001, 0.01, 0.1, 1.0, 5.0, 10.0]
            ),
            MetricDefinition(
                "health_check_failures_total",
                MetricType.COUNTER,
                "Nombre total d'√©checs de health checks",
                ["component"]
            )
        ]
        
        for metric_def in health_metrics:
            if metric_def.name not in self.metrics_collector._metrics:
                self.metrics_collector.register_metric(metric_def)
    
    async def _start_health_monitoring(self) -> None:
        """D√©marre le monitoring de sant√©."""
        self._health_monitoring_task = asyncio.create_task(self._health_monitoring_loop())
    
    def register_health_check(self, health_check: HealthCheck) -> None:
        """Enregistre un nouveau health check."""
        
        self._health_checks[health_check.name] = health_check
        self._health_status[health_check.name] = HealthStatus.UNKNOWN
        
        logger.info(
            "Health check enregistr√©",
            name=health_check.name,
            interval=health_check.interval,
            critical=health_check.critical
        )
    
    async def _health_monitoring_loop(self) -> None:
        """Boucle principale de monitoring de sant√©."""
        
        # Stockage des derni√®res v√©rifications
        last_checks: Dict[str, float] = {}
        
        while True:
            try:
                current_time = time.time()
                
                for check_name, health_check in self._health_checks.items():
                    if not health_check.enabled:
                        continue
                    
                    # V√©rification de l'intervalle
                    last_check = last_checks.get(check_name, 0)
                    if current_time - last_check < health_check.interval:
                        continue
                    
                    # Ex√©cution du check
                    await self._execute_health_check(health_check)
                    last_checks[check_name] = current_time
                
                # Mise √† jour de la sant√© globale
                self._update_global_health()
                
                await asyncio.sleep(5)  # V√©rification toutes les 5 secondes
                
            except Exception as e:
                logger.error("Erreur dans la boucle de health monitoring", error=str(e))
                await asyncio.sleep(30)
    
    async def _execute_health_check(self, health_check: HealthCheck) -> None:
        """Ex√©cute un health check sp√©cifique."""
        
        start_time = time.time()
        
        try:
            # Ex√©cution avec timeout et retries
            for attempt in range(health_check.retries + 1):
                try:
                    status, message = await asyncio.wait_for(
                        health_check.check_function(),
                        timeout=health_check.timeout
                    )
                    break
                except asyncio.TimeoutError:
                    if attempt == health_check.retries:
                        status = HealthStatus.UNHEALTHY
                        message = f"Timeout apr√®s {health_check.timeout}s"
                    else:
                        await asyncio.sleep(1)  # Attente avant retry
                        continue
                except Exception as e:
                    if attempt == health_check.retries:
                        status = HealthStatus.UNHEALTHY
                        message = f"Erreur: {str(e)}"
                    else:
                        await asyncio.sleep(1)
                        continue
            
            # Mise √† jour du statut
            previous_status = self._health_status.get(health_check.name)
            self._health_status[health_check.name] = status
            
            # Ajout √† l'historique
            health_record = {
                "timestamp": time.time(),
                "status": status,
                "message": message,
                "duration": time.time() - start_time
            }
            self._health_history[health_check.name].append(health_record)
            
            # M√©triques
            status_value = {"healthy": 2, "degraded": 1, "unhealthy": 0, "unknown": -1}[status.value]
            self.metrics_collector.set_gauge(
                "component_health_status",
                status_value,
                {"component": health_check.name}
            )
            
            self.metrics_collector.observe_histogram(
                "health_check_duration_seconds",
                time.time() - start_time,
                {"component": health_check.name}
            )
            
            if status == HealthStatus.UNHEALTHY:
                self.metrics_collector.increment_counter(
                    "health_check_failures_total",
                    labels={"component": health_check.name}
                )
            
            # Log des changements de statut
            if previous_status and previous_status != status:
                logger.info(
                    "Changement de statut de sant√©",
                    component=health_check.name,
                    previous_status=previous_status.value,
                    new_status=status.value,
                    message=message
                )
        
        except Exception as e:
            logger.error(
                "Erreur lors de l'ex√©cution du health check",
                component=health_check.name,
                error=str(e)
            )
            
            # Statut d'erreur
            self._health_status[health_check.name] = HealthStatus.UNKNOWN
    
    def _update_global_health(self) -> None:
        """Met √† jour la sant√© globale du syst√®me."""
        
        if not self._health_status:
            self._global_health = HealthStatus.UNKNOWN
            return
        
        # V√©rification des composants critiques
        critical_components = [
            name for name, check in self._health_checks.items()
            if check.critical and check.enabled
        ]
        
        critical_unhealthy = any(
            self._health_status.get(name) == HealthStatus.UNHEALTHY
            for name in critical_components
        )
        
        if critical_unhealthy:
            self._global_health = HealthStatus.UNHEALTHY
            return
        
        # V√©rification de la d√©gradation
        degraded_count = sum(
            1 for status in self._health_status.values()
            if status == HealthStatus.DEGRADED
        )
        
        unhealthy_count = sum(
            1 for status in self._health_status.values()
            if status == HealthStatus.UNHEALTHY
        )
        
        total_components = len(self._health_status)
        
        if unhealthy_count > 0 or degraded_count > (total_components * 0.3):
            self._global_health = HealthStatus.DEGRADED
        elif all(status == HealthStatus.HEALTHY for status in self._health_status.values()):
            self._global_health = HealthStatus.HEALTHY
        else:
            self._global_health = HealthStatus.DEGRADED
    
    def get_health_status(self, component_name: Optional[str] = None) -> Union[HealthStatus, Dict[str, HealthStatus]]:
        """Retourne le statut de sant√© d'un composant ou global."""
        
        if component_name:
            return self._health_status.get(component_name, HealthStatus.UNKNOWN)
        else:
            return {
                "global": self._global_health,
                **self._health_status
            }
    
    def get_health_report(self) -> Dict[str, Any]:
        """G√©n√®re un rapport de sant√© d√©taill√©."""
        
        # Statistiques globales
        total_components = len(self._health_checks)
        healthy_count = sum(1 for s in self._health_status.values() if s == HealthStatus.HEALTHY)
        degraded_count = sum(1 for s in self._health_status.values() if s == HealthStatus.DEGRADED)
        unhealthy_count = sum(1 for s in self._health_status.values() if s == HealthStatus.UNHEALTHY)
        
        # Composants probl√©matiques
        problematic_components = []
        for name, status in self._health_status.items():
            if status in [HealthStatus.DEGRADED, HealthStatus.UNHEALTHY]:
                recent_history = list(self._health_history[name])[-5:]
                problematic_components.append({
                    "name": name,
                    "status": status.value,
                    "critical": self._health_checks[name].critical,
                    "recent_history": [
                        {
                            "timestamp": record["timestamp"],
                            "status": record["status"].value,
                            "message": record["message"]
                        }
                        for record in recent_history
                    ]
                })
        
        return {
            "global_health": self._global_health.value,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "summary": {
                "total_components": total_components,
                "healthy": healthy_count,
                "degraded": degraded_count,
                "unhealthy": unhealthy_count,
                "health_percentage": (healthy_count / total_components * 100) if total_components > 0 else 0
            },
            "problematic_components": problematic_components,
            "recommendations": self._generate_health_recommendations()
        }
    
    def _generate_health_recommendations(self) -> List[str]:
        """G√©n√®re des recommandations bas√©es sur l'√©tat de sant√©."""
        
        recommendations = []
        
        # Analyse des patterns de d√©faillance
        for name, history in self._health_history.items():
            recent_failures = [
                record for record in list(history)[-10:]
                if record["status"] == HealthStatus.UNHEALTHY
            ]
            
            if len(recent_failures) >= 3:
                recommendations.append(
                    f"Composant {name}: √âchecs fr√©quents d√©tect√©s, "
                    "v√©rifier la configuration et les d√©pendances"
                )
        
        # V√©rifications de performance
        for name, history in self._health_history.items():
            recent_records = list(history)[-5:]
            if recent_records:
                avg_duration = np.mean([r["duration"] for r in recent_records])
                if avg_duration > 5.0:  # Plus de 5 secondes
                    recommendations.append(
                        f"Composant {name}: Health checks lents (avg: {avg_duration:.2f}s), "
                        "optimiser les v√©rifications"
                    )
        
        # √âtat global
        if self._global_health == HealthStatus.DEGRADED:
            recommendations.append(
                "Syst√®me en √©tat d√©grad√©: Examiner les composants probl√©matiques "
                "et leurs interd√©pendances"
            )
        elif self._global_health == HealthStatus.UNHEALTHY:
            recommendations.append(
                "Syst√®me critique: Intervention imm√©diate requise sur les "
                "composants critiques d√©faillants"
            )
        
        return recommendations


# Fonctions d'aide pour la cr√©ation de health checks
async def database_health_check(connection_string: str) -> Tuple[HealthStatus, str]:
    """Health check pour base de donn√©es PostgreSQL."""
    try:
        conn = await asyncpg.connect(connection_string)
        await conn.execute("SELECT 1")
        await conn.close()
        return HealthStatus.HEALTHY, "Base de donn√©es accessible"
    except Exception as e:
        return HealthStatus.UNHEALTHY, f"Erreur DB: {str(e)}"


async def redis_health_check(redis_url: str) -> Tuple[HealthStatus, str]:
    """Health check pour Redis."""
    try:
        redis = aioredis.from_url(redis_url)
        await redis.ping()
        await redis.close()
        return HealthStatus.HEALTHY, "Redis accessible"
    except Exception as e:
        return HealthStatus.UNHEALTHY, f"Erreur Redis: {str(e)}"


async def http_endpoint_health_check(url: str, timeout: int = 5) -> Tuple[HealthStatus, str]:
    """Health check pour endpoint HTTP."""
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=timeout) as response:
                if response.status == 200:
                    return HealthStatus.HEALTHY, f"Endpoint accessible (status: {response.status})"
                else:
                    return HealthStatus.DEGRADED, f"Status non optimal: {response.status}"
    except Exception as e:
        return HealthStatus.UNHEALTHY, f"Erreur endpoint: {str(e)}"


async def disk_space_health_check(path: str, warning_threshold: float = 80.0, critical_threshold: float = 90.0) -> Tuple[HealthStatus, str]:
    """Health check pour l'espace disque."""
    try:
        disk_usage = psutil.disk_usage(path)
        usage_percent = (disk_usage.used / disk_usage.total) * 100
        
        if usage_percent >= critical_threshold:
            return HealthStatus.UNHEALTHY, f"Espace disque critique: {usage_percent:.1f}%"
        elif usage_percent >= warning_threshold:
            return HealthStatus.DEGRADED, f"Espace disque faible: {usage_percent:.1f}%"
        else:
            return HealthStatus.HEALTHY, f"Espace disque OK: {usage_percent:.1f}%"
    except Exception as e:
        return HealthStatus.UNKNOWN, f"Erreur v√©rification disque: {str(e)}"


async def memory_health_check(warning_threshold: float = 80.0, critical_threshold: float = 90.0) -> Tuple[HealthStatus, str]:
    """Health check pour l'utilisation m√©moire."""
    try:
        memory = psutil.virtual_memory()
        usage_percent = memory.percent
        
        if usage_percent >= critical_threshold:
            return HealthStatus.UNHEALTHY, f"M√©moire critique: {usage_percent:.1f}%"
        elif usage_percent >= warning_threshold:
            return HealthStatus.DEGRADED, f"M√©moire √©lev√©e: {usage_percent:.1f}%"
        else:
            return HealthStatus.HEALTHY, f"M√©moire OK: {usage_percent:.1f}%"
    except Exception as e:
        return HealthStatus.UNKNOWN, f"Erreur v√©rification m√©moire: {str(e)}"


# Instances globales
global_metrics_collector = MetricsCollector()
global_alert_manager = AlertManager(global_metrics_collector)
global_health_monitor = HealthMonitor(global_metrics_collector)


# Configuration par d√©faut
def setup_default_monitoring():
    """Configure le monitoring par d√©faut."""
    
    # Enregistrement des m√©triques business
    business_metrics = [
        MetricDefinition(
            "data_collection_operations_total",
            MetricType.COUNTER,
            "Nombre total d'op√©rations de collecte",
            ["collector_type", "tenant_id", "status"]
        ),
        MetricDefinition(
            "data_collection_duration_seconds",
            MetricType.HISTOGRAM,
            "Dur√©e des op√©rations de collecte",
            ["collector_type", "tenant_id"],
            buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0]
        ),
        MetricDefinition(
            "data_records_processed_total",
            MetricType.COUNTER,
            "Nombre total d'enregistrements trait√©s",
            ["collector_type", "tenant_id"]
        ),
        MetricDefinition(
            "data_size_bytes_total",
            MetricType.COUNTER,
            "Taille totale des donn√©es collect√©es en bytes",
            ["collector_type", "tenant_id"]
        ),
        MetricDefinition(
            "active_collectors",
            MetricType.GAUGE,
            "Nombre de collecteurs actifs",
            ["type"]
        )
    ]
    
    for metric_def in business_metrics:
        global_metrics_collector.register_metric(metric_def)
    
    # Alertes par d√©faut
    default_alerts = [
        AlertRule(
            name="high_cpu_usage",
            metric_name="spotify_ai_agent_collectors_cpu_usage_percent",
            condition=">",
            threshold=80.0,
            duration=300,  # 5 minutes
            severity=AlertSeverity.WARNING,
            description="Utilisation CPU √©lev√©e d√©tect√©e"
        ),
        AlertRule(
            name="critical_cpu_usage",
            metric_name="spotify_ai_agent_collectors_cpu_usage_percent",
            condition=">",
            threshold=95.0,
            duration=60,  # 1 minute
            severity=AlertSeverity.CRITICAL,
            description="Utilisation CPU critique d√©tect√©e"
        ),
        AlertRule(
            name="high_memory_usage",
            metric_name="spotify_ai_agent_collectors_memory_usage_percent",
            condition=">",
            threshold=85.0,
            duration=300,
            severity=AlertSeverity.WARNING,
            description="Utilisation m√©moire √©lev√©e d√©tect√©e"
        ),
        AlertRule(
            name="data_collection_failures",
            metric_name="spotify_ai_agent_collectors_data_collection_operations_total",
            condition=">",
            threshold=10.0,
            duration=300,
            severity=AlertSeverity.WARNING,
            description="Taux d'√©chec de collecte √©lev√© d√©tect√©"
        )
    ]
    
    for alert_rule in default_alerts:
        global_alert_manager.register_alert_rule(alert_rule)
    
    # Health checks par d√©faut
    default_health_checks = [
        HealthCheck(
            name="memory_check",
            check_function=memory_health_check,
            interval=60,
            critical=True
        ),
        HealthCheck(
            name="disk_check",
            check_function=lambda: disk_space_health_check("/"),
            interval=300,  # 5 minutes
            critical=True
        )
    ]
    
    for health_check in default_health_checks:
        global_health_monitor.register_health_check(health_check)


# Initialisation automatique
setup_default_monitoring()
