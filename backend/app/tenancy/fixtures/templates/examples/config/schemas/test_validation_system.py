#!/usr/bin/env python3
"""
Suite de tests automatisÃ©s pour le systÃ¨me de validation ultra-avancÃ©
CrÃ©Ã© par l'Ã©quipe d'experts dirigÃ©e par Fahed Mlaiel

Tests complets pour valider l'ensemble des fonctionnalitÃ©s enterprise
"""

import pytest
import asyncio
import json
import tempfile
from pathlib import Path
from typing import Dict, Any

# Import du systÃ¨me de validation
from . import EnterpriseSchemaManager, ValidationResult, SchemaType, DataFormat


class TestEnterpriseSchemaValidation:
    """Suite de tests pour le systÃ¨me de validation enterprise"""
    
    @pytest.fixture
    async def schema_manager(self):
        """Fixture pour initialiser le gestionnaire de schÃ©mas"""
        manager = EnterpriseSchemaManager()
        
        # Chargement des schÃ©mas de test
        schemas_dir = Path(__file__).parent
        test_schemas = [
            ("user_profile", "user_profile_schema.json"),
            ("api", "api_schema.json"),
            ("security", "security_schema.json"),
            ("ml_model", "ml_model_schema.json"),
            ("environment", "environment_schema.json")
        ]
        
        for schema_id, filename in test_schemas:
            schema_path = schemas_dir / filename
            if schema_path.exists():
                await manager.load_schema_from_file(
                    schema_id=schema_id,
                    file_path=str(schema_path),
                    schema_type=SchemaType.JSON_SCHEMA
                )
        
        return manager
    
    @pytest.mark.asyncio
    async def test_valid_user_profile(self, schema_manager):
        """Test de validation d'un profil utilisateur valide"""
        valid_user = {
            "user_id": "test_user_123",
            "profile_data": {
                "email": "test@example.com",
                "username": "testuser",
                "created_at": "2024-01-15T10:30:00Z",
                "status": "active"
            },
            "preferences": {
                "music_preferences": {
                    "favorite_genres": ["pop", "rock"],
                    "discovery_mode": "moderate"
                },
                "ai_preferences": {
                    "personalization_level": "standard"
                }
            },
            "privacy_settings": {
                "data_sharing_consent": {
                    "marketing": False,
                    "analytics": True,
                    "third_party": False
                },
                "analytics_consent": {
                    "behavioral_analytics": True
                }
            }
        }
        
        result = await schema_manager.validate_data(
            data=valid_user,
            schema_id="user_profile"
        )
        
        assert result.is_valid, f"Validation Ã©chouÃ©e: {result.errors}"
        assert len(result.errors) == 0
    
    @pytest.mark.asyncio
    async def test_invalid_user_profile(self, schema_manager):
        """Test de validation d'un profil utilisateur invalide"""
        invalid_user = {
            "user_id": "ab",  # Trop court
            "profile_data": {
                "email": "invalid-email",  # Format invalide
                "created_at": "invalid-date"
            },
            "preferences": {},  # DonnÃ©es manquantes
            "privacy_settings": {}  # DonnÃ©es manquantes
        }
        
        result = await schema_manager.validate_data(
            data=invalid_user,
            schema_id="user_profile"
        )
        
        assert not result.is_valid
        assert len(result.errors) > 0
    
    @pytest.mark.asyncio
    async def test_ai_suggestions(self, schema_manager):
        """Test des suggestions IA pour donnÃ©es invalides"""
        invalid_data = {
            "user_id": "short",
            "profile_data": {
                "email": "bad-email",
                "created_at": "2024-01-15T10:30:00Z"
            },
            "preferences": {
                "music_preferences": {},
                "ai_preferences": {}
            },
            "privacy_settings": {
                "data_sharing_consent": {
                    "marketing": False,
                    "analytics": True,
                    "third_party": False
                },
                "analytics_consent": {
                    "behavioral_analytics": True
                }
            }
        }
        
        result = await schema_manager.validate_data(
            data=invalid_data,
            schema_id="user_profile",
            enable_ai_suggestions=True
        )
        
        assert not result.is_valid
        assert len(result.ai_suggestions) > 0
    
    @pytest.mark.asyncio
    async def test_ml_model_validation(self, schema_manager):
        """Test de validation d'une configuration ML"""
        ml_config = {
            "model_info": {
                "name": "test_model",
                "version": "1.0.0",
                "type": "recommendation",
                "framework": "pytorch",
                "description": "Test model for validation"
            },
            "training_config": {
                "data_source": {
                    "type": "database",
                    "location": "test://localhost/db"
                },
                "hyperparameters": {
                    "learning_rate": 0.001,
                    "batch_size": 32
                }
            },
            "deployment_config": {
                "environment": "development",
                "serving": {
                    "type": "online"
                }
            },
            "monitoring": {
                "metrics": {},
                "logging": {}
            }
        }
        
        result = await schema_manager.validate_data(
            data=ml_config,
            schema_id="ml_model"
        )
        
        assert result.is_valid, f"Validation ML Ã©chouÃ©e: {result.errors}"
    
    @pytest.mark.asyncio
    async def test_api_configuration_validation(self, schema_manager):
        """Test de validation d'une configuration API"""
        api_config = {
            "api_version": "v1.0",
            "endpoints": {
                "/test": {
                    "methods": ["GET"],
                    "description": "Test endpoint for validation"
                }
            },
            "authentication": {
                "schemes": [
                    {
                        "type": "jwt",
                        "name": "Bearer Auth"
                    }
                ]
            },
            "rate_limiting": {
                "global_limits": {
                    "requests_per_second": 10
                }
            },
            "monitoring": {
                "metrics": {},
                "health_checks": {}
            }
        }
        
        result = await schema_manager.validate_data(
            data=api_config,
            schema_id="api"
        )
        
        assert result.is_valid, f"Validation API Ã©chouÃ©e: {result.errors}"
    
    @pytest.mark.asyncio
    async def test_security_configuration(self, schema_manager):
        """Test de validation d'une configuration de sÃ©curitÃ©"""
        security_config = {
            "authentication": {
                "primary_method": "jwt",
                "mfa": {
                    "enabled": True
                },
                "session_management": {
                    "timeout_minutes": 60
                }
            },
            "authorization": {
                "rbac": {
                    "enabled": True
                },
                "permissions": {}
            },
            "encryption": {
                "data_at_rest": {
                    "enabled": True,
                    "algorithm": "AES-256-GCM"
                },
                "data_in_transit": {
                    "tls_version": "1.3",
                    "cipher_suites": ["TLS_AES_256_GCM_SHA384"]
                }
            },
            "monitoring": {
                "security_events": {},
                "anomaly_detection": {}
            }
        }
        
        result = await schema_manager.validate_data(
            data=security_config,
            schema_id="security"
        )
        
        assert result.is_valid, f"Validation sÃ©curitÃ© Ã©chouÃ©e: {result.errors}"
    
    @pytest.mark.asyncio
    async def test_batch_validation(self, schema_manager):
        """Test de validation en lot"""
        test_users = [
            {
                "user_id": f"user_{i}",
                "profile_data": {
                    "email": f"user{i}@example.com",
                    "created_at": "2024-01-15T10:30:00Z"
                },
                "preferences": {
                    "music_preferences": {},
                    "ai_preferences": {}
                },
                "privacy_settings": {
                    "data_sharing_consent": {
                        "marketing": False,
                        "analytics": True,
                        "third_party": False
                    },
                    "analytics_consent": {
                        "behavioral_analytics": True
                    }
                }
            }
            for i in range(10)
        ]
        
        results = await schema_manager.validate_batch(
            data_list=test_users,
            schema_id="user_profile"
        )
        
        assert len(results) == 10
        assert all(result.is_valid for result in results)
    
    @pytest.mark.asyncio
    async def test_multi_format_validation(self, schema_manager):
        """Test de validation multi-format"""
        test_data = {"test": "data"}
        
        # Test JSON
        json_result = await schema_manager.validate_multi_format(
            data=json.dumps(test_data),
            data_format=DataFormat.JSON
        )
        assert json_result is not None
        
        # Test YAML
        yaml_data = "test: data\nvalid: true"
        yaml_result = await schema_manager.validate_multi_format(
            data=yaml_data,
            data_format=DataFormat.YAML
        )
        assert yaml_result is not None
    
    @pytest.mark.asyncio
    async def test_performance_metrics(self, schema_manager):
        """Test des mÃ©triques de performance"""
        # Effectuer quelques validations
        test_data = {
            "user_id": "perf_test_user",
            "profile_data": {
                "email": "perf@example.com",
                "created_at": "2024-01-15T10:30:00Z"
            },
            "preferences": {
                "music_preferences": {},
                "ai_preferences": {}
            },
            "privacy_settings": {
                "data_sharing_consent": {
                    "marketing": False,
                    "analytics": True,
                    "third_party": False
                },
                "analytics_consent": {
                    "behavioral_analytics": True
                }
            }
        }
        
        # Plusieurs validations pour gÃ©nÃ©rer des mÃ©triques
        for _ in range(5):
            await schema_manager.validate_data(
                data=test_data,
                schema_id="user_profile"
            )
        
        metrics = await schema_manager.get_performance_metrics()
        
        assert metrics is not None
        assert "total_validations" in metrics
        assert metrics["total_validations"] >= 5
    
    @pytest.mark.asyncio
    async def test_schema_loading_errors(self, schema_manager):
        """Test de gestion des erreurs de chargement de schÃ©mas"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            f.write('{"invalid": json}')  # JSON invalide
            invalid_schema_path = f.name
        
        try:
            with pytest.raises(Exception):
                await schema_manager.load_schema_from_file(
                    schema_id="invalid_schema",
                    file_path=invalid_schema_path,
                    schema_type=SchemaType.JSON_SCHEMA
                )
        finally:
            Path(invalid_schema_path).unlink()  # Nettoyer le fichier temporaire
    
    @pytest.mark.asyncio
    async def test_custom_validation_rules(self, schema_manager):
        """Test des rÃ¨gles de validation personnalisÃ©es"""
        # Test avec une rÃ¨gle personnalisÃ©e
        custom_data = {
            "user_id": "custom_validation_test",
            "profile_data": {
                "email": "custom@example.com",
                "created_at": "2024-01-15T10:30:00Z"
            },
            "preferences": {
                "music_preferences": {
                    "favorite_genres": ["pop"] * 15  # Trop de genres (limite: 10)
                },
                "ai_preferences": {}
            },
            "privacy_settings": {
                "data_sharing_consent": {
                    "marketing": False,
                    "analytics": True,
                    "third_party": False
                },
                "analytics_consent": {
                    "behavioral_analytics": True
                }
            }
        }
        
        result = await schema_manager.validate_data(
            data=custom_data,
            schema_id="user_profile"
        )
        
        # Devrait Ã©chouer Ã  cause de la limite sur favorite_genres
        assert not result.is_valid
        assert any("favorite_genres" in str(error) for error in result.errors)


@pytest.mark.asyncio
async def test_enterprise_features_integration():
    """Test d'intÃ©gration des fonctionnalitÃ©s enterprise"""
    manager = EnterpriseSchemaManager()
    
    # Test que toutes les fonctionnalitÃ©s enterprise sont disponibles
    assert hasattr(manager, 'validate_data')
    assert hasattr(manager, 'validate_batch')
    assert hasattr(manager, 'validate_multi_format')
    assert hasattr(manager, 'get_performance_metrics')
    assert hasattr(manager, 'load_schema_from_file')
    
    # Test des Ã©numÃ©rations
    assert SchemaType.JSON_SCHEMA
    assert DataFormat.JSON
    assert DataFormat.YAML
    assert DataFormat.XML


if __name__ == "__main__":
    """ExÃ©cution directe des tests pour validation rapide"""
    import sys
    
    print("ğŸ§ª Lancement des tests automatisÃ©s du systÃ¨me enterprise")
    print("=" * 60)
    
    # ExÃ©cution simple sans pytest pour dÃ©monstration
    async def run_basic_tests():
        manager = EnterpriseSchemaManager()
        
        print("âœ… Test 1: Initialisation du gestionnaire - OK")
        
        # Test basique de validation
        test_data = {"test": "data"}
        try:
            # Ce test Ã©chouera car aucun schÃ©ma n'est chargÃ©, mais teste la mÃ©thode
            result = await manager.validate_data(test_data, "non_existent_schema")
            print("âŒ Test 2: Validation avec schÃ©ma inexistant - Attendu")
        except Exception:
            print("âœ… Test 2: Gestion d'erreur schÃ©ma inexistant - OK")
        
        print("âœ… Test 3: MÃ©thodes enterprise disponibles - OK")
        
        metrics = await manager.get_performance_metrics()
        print(f"âœ… Test 4: MÃ©triques de performance - {type(metrics)}")
        
        print("\nğŸ‰ Tests basiques terminÃ©s avec succÃ¨s!")
        print("ğŸ’¡ Utilisez 'pytest' pour la suite complÃ¨te de tests")
    
    # ExÃ©cution
    if len(sys.argv) > 1 and sys.argv[1] == "--basic":
        asyncio.run(run_basic_tests())
    else:
        print("ğŸ’¡ Pour lancer les tests complets: pytest test_validation_system.py")
        print("ğŸ’¡ Pour les tests basiques: python test_validation_system.py --basic")
